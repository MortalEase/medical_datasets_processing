import os
from pathlib import Path
import argparse
import yaml
import random
from prettytable import PrettyTable


def get_image_extensions():
    """è¿”å›æ”¯æŒçš„å›¾ç‰‡æ ¼å¼æ‰©å±•å"""
    return ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp']


def find_classes_file(dataset_dir):
    """æŸ¥æ‰¾classes.txtæ–‡ä»¶"""
    possible_paths = [
        os.path.join(dataset_dir, 'classes.txt'),
        os.path.join(dataset_dir, 'obj.names'),
        os.path.join(dataset_dir, 'names.txt'),
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    return None


def find_data_yaml(dataset_dir):
    """æŸ¥æ‰¾data.yamlæ–‡ä»¶"""
    possible_paths = [
        os.path.join(dataset_dir, 'data.yaml'),
        os.path.join(dataset_dir, 'data.yml'),
        os.path.join(dataset_dir, 'dataset.yaml'),
        os.path.join(dataset_dir, 'dataset.yml'),
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    return None


def load_class_names(dataset_dir):
    """åŠ è½½ç±»åˆ«åç§°"""
    # ä¼˜å…ˆæŸ¥æ‰¾data.yaml
    yaml_path = find_data_yaml(dataset_dir)
    if yaml_path:
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                if 'names' in data:
                    if isinstance(data['names'], list):
                        return {i: name for i, name in enumerate(data['names'])}
                    elif isinstance(data['names'], dict):
                        return data['names']
        except:
            pass
    
    # æŸ¥æ‰¾classes.txt
    classes_path = find_classes_file(dataset_dir)
    if classes_path:
        try:
            with open(classes_path, 'r', encoding='utf-8') as f:
                names = [line.strip() for line in f if line.strip()]
                return {i: name for i, name in enumerate(names)}
        except:
            pass
    
    return {}


def detect_dataset_structure(dataset_dir):
    """æ£€æµ‹æ•°æ®é›†ç»“æ„ç±»å‹"""
    # æ£€æŸ¥æ ¼å¼ä¸€ï¼šdataset/train/images/ + dataset/train/labels/ ç­‰
    train_images = os.path.join(dataset_dir, 'train', 'images')
    train_labels = os.path.join(dataset_dir, 'train', 'labels')
    val_images = os.path.join(dataset_dir, 'val', 'images')
    val_labels = os.path.join(dataset_dir, 'val', 'labels')
    test_images = os.path.join(dataset_dir, 'test', 'images')
    test_labels = os.path.join(dataset_dir, 'test', 'labels')
    
    if (os.path.exists(train_images) and os.path.exists(train_labels)) or \
       (os.path.exists(val_images) and os.path.exists(val_labels)) or \
       (os.path.exists(test_images) and os.path.exists(test_labels)):
        return 'format1'  # æ ¼å¼ä¸€
    
    # æ£€æŸ¥æ ¼å¼äºŒï¼šdataset/images/train/ + dataset/labels/train/ ç­‰
    images_train = os.path.join(dataset_dir, 'images', 'train')
    labels_train = os.path.join(dataset_dir, 'labels', 'train')
    images_val = os.path.join(dataset_dir, 'images', 'val')
    labels_val = os.path.join(dataset_dir, 'labels', 'val')
    images_test = os.path.join(dataset_dir, 'images', 'test')
    labels_test = os.path.join(dataset_dir, 'labels', 'test')
    
    if (os.path.exists(images_train) and os.path.exists(labels_train)) or \
       (os.path.exists(images_val) and os.path.exists(labels_val)) or \
       (os.path.exists(images_test) and os.path.exists(labels_test)):
        return 'format2'  # æ ¼å¼äºŒ
    
    # æ£€æŸ¥ç®€å•ç»“æ„ï¼šdataset/images/ + dataset/labels/
    images_dir = os.path.join(dataset_dir, 'images')
    labels_dir = os.path.join(dataset_dir, 'labels')
    if os.path.exists(images_dir) and os.path.exists(labels_dir):
        return 'simple'  # ç®€å•ç»“æ„
    
    # æ£€æŸ¥æ··åˆç»“æ„ï¼šæ‰€æœ‰å›¾ç‰‡å’Œtxtæ–‡ä»¶åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­
    img_exts = get_image_extensions()
    txt_files = []
    img_files = []
    
    try:
        for file in os.listdir(dataset_dir):
            file_path = os.path.join(dataset_dir, file)
            if os.path.isfile(file_path):
                if Path(file).suffix.lower() in img_exts:
                    img_files.append(file)
                elif Path(file).suffix.lower() == '.txt' and file not in ['classes.txt', 'obj.names', 'names.txt']:
                    txt_files.append(file)
        
        # å¦‚æœå­˜åœ¨å›¾ç‰‡æ–‡ä»¶å’Œtxtæ–‡ä»¶ï¼Œåˆ™è®¤ä¸ºæ˜¯æ··åˆç»“æ„
        if img_files and txt_files:
            return 'mixed'  # æ··åˆç»“æ„
    except:
        pass
    
    return 'unknown'


def get_dataset_paths(dataset_dir):
    """æ ¹æ®æ•°æ®é›†ç»“æ„è·å–æ‰€æœ‰imageså’Œlabelsè·¯å¾„"""
    structure = detect_dataset_structure(dataset_dir)
    paths = []
    
    if structure == 'format1':
        # æ ¼å¼ä¸€ï¼šdataset/train/images/ + dataset/train/labels/ ç­‰
        for split in ['train', 'val', 'test']:
            images_dir = os.path.join(dataset_dir, split, 'images')
            labels_dir = os.path.join(dataset_dir, split, 'labels')
            if os.path.exists(images_dir) and os.path.exists(labels_dir):
                paths.append((split, images_dir, labels_dir))
    elif structure == 'format2':
        # æ ¼å¼äºŒï¼šdataset/images/train/ + dataset/labels/train/ ç­‰
        for split in ['train', 'val', 'test']:
            images_dir = os.path.join(dataset_dir, 'images', split)
            labels_dir = os.path.join(dataset_dir, 'labels', split)
            if os.path.exists(images_dir) and os.path.exists(labels_dir):
                paths.append((split, images_dir, labels_dir))
    elif structure == 'simple':
        # ç®€å•ç»“æ„ï¼šdataset/images/ + dataset/labels/
        images_dir = os.path.join(dataset_dir, 'images')
        labels_dir = os.path.join(dataset_dir, 'labels')
        paths.append(('dataset', images_dir, labels_dir))
    elif structure == 'mixed':
        # æ··åˆç»“æ„ï¼šæ‰€æœ‰å›¾ç‰‡å’Œtxtæ–‡ä»¶åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­
        paths.append(('dataset', dataset_dir, dataset_dir))
    
    return structure, paths


def check_yolo_dataset(img_dir, label_dir, img_exts=None):
    """
    æ£€æŸ¥YOLOæ•°æ®é›†å›¾ç‰‡ä¸æ ‡æ³¨çš„å¯¹åº”å…³ç³»
    """
    if img_exts is None:
        img_exts = get_image_extensions()
    
    # å¤„ç†æ··åˆç»“æ„ï¼ˆå›¾ç‰‡å’Œæ ‡ç­¾åœ¨åŒä¸€ç›®å½•ï¼‰
    if img_dir == label_dir:
        all_files = os.listdir(img_dir)
        
        # è·å–å›¾ç‰‡æ–‡ä»¶åé›†åˆï¼ˆä¸å«æ‰©å±•åï¼‰
        img_stems = set()
        for f in all_files:
            if Path(f).suffix.lower() in img_exts:
                img_stems.add(Path(f).stem)
        
        # è·å–æ ‡ç­¾æ–‡ä»¶åé›†åˆï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œæ’é™¤ç±»åˆ«æ–‡ä»¶
        label_stems = set()
        for f in all_files:
            if (Path(f).suffix.lower() == '.txt' and 
                f not in ['classes.txt', 'obj.names', 'names.txt', 'data.yaml', 'data.yml']):
                label_stems.add(Path(f).stem)
    else:
        # å¤„ç†åˆ†ç¦»ç»“æ„ï¼ˆå›¾ç‰‡å’Œæ ‡ç­¾åœ¨ä¸åŒç›®å½•ï¼‰
        # è·å–æ–‡ä»¶åé›†åˆï¼ˆä¸å«æ‰©å±•åï¼‰
        img_stems = {Path(f).stem for f in os.listdir(img_dir)
                     if Path(f).suffix.lower() in img_exts}

        label_stems = {Path(f).stem for f in os.listdir(label_dir)
                       if Path(f).suffix.lower() == '.txt'}

    # è®¡ç®—å·®å¼‚é›†åˆ
    missing_labels = img_stems - label_stems
    redundant_labels = label_stems - img_stems

    # ç”Ÿæˆå®Œæ•´æ–‡ä»¶ååˆ—è¡¨
    missing_files = []
    for stem in missing_labels:
        for ext in img_exts:
            f = Path(img_dir) / (stem + ext)
            if f.exists():
                missing_files.append(str(f))
                break

    redundant_files = [str(Path(label_dir) / (stem + '.txt'))
                       for stem in redundant_labels]

    return missing_files, redundant_files


def generate_report(split_name, missing, redundant):
    """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
    print(f"\n{'=' * 20} {split_name} æ£€æŸ¥æŠ¥å‘Š {'=' * 20}")
    print(f"ç¼ºå¤±æ ‡æ³¨æ–‡ä»¶: {len(missing)} ä¸ª")
    print(f"å†—ä½™æ ‡æ³¨æ–‡ä»¶: {len(redundant)} ä¸ª")

    if missing:
        print("\n[ ç¼ºå¤±æ ‡æ³¨çš„å›¾ç‰‡ ]")
        for f in missing[:5]:  # æœ€å¤šæ˜¾ç¤ºå‰5ä¸ª
            print(f"  ! {os.path.basename(f)}")
        if len(missing) > 5: 
            print(f"  ...ï¼ˆè¿˜æœ‰{len(missing)-5}ä¸ªï¼‰")

    if redundant:
        print("\n[ å†—ä½™çš„æ ‡æ³¨æ–‡ä»¶ ]")
        for f in redundant[:5]:
            print(f"  x {os.path.basename(f)}")
        if len(redundant) > 5: 
            print(f"  ...ï¼ˆè¿˜æœ‰{len(redundant)-5}ä¸ªï¼‰")


def analyze_annotation_statistics(img_dir, label_dir, split_name="", class_names=None):
    """åˆ†ææ ‡æ³¨ç»Ÿè®¡ä¿¡æ¯"""
    img_exts = get_image_extensions()
    total_images = 0
    labeled_images = 0
    total_boxes = 0
    class_counts = {}
    box_counts_per_image = []
    
    # å¤„ç†æ··åˆç»“æ„ï¼ˆå›¾ç‰‡å’Œæ ‡ç­¾åœ¨åŒä¸€ç›®å½•ï¼‰
    if img_dir == label_dir:
        all_files = os.listdir(img_dir)
        
        for f in all_files:
            if Path(f).suffix.lower() in img_exts:
                total_images += 1
                label_path = Path(img_dir) / (Path(f).stem + '.txt')
                
                # ç¡®ä¿ä¸æ˜¯ç±»åˆ«æ–‡ä»¶
                if (label_path.exists() and 
                    label_path.name not in ['classes.txt', 'obj.names', 'names.txt']):
                    labeled_images += 1
                    boxes_in_image = 0
                    
                    try:
                        with open(label_path, 'r') as file:
                            for line in file:
                                parts = line.strip().split()
                                if len(parts) >= 5:
                                    class_id = int(float(parts[0]))
                                    boxes_in_image += 1
                                    total_boxes += 1
                                    class_counts[class_id] = class_counts.get(class_id, 0) + 1
                    except:
                        continue
                    
                    box_counts_per_image.append(boxes_in_image)
    else:
        # å¤„ç†åˆ†ç¦»ç»“æ„ï¼ˆå›¾ç‰‡å’Œæ ‡ç­¾åœ¨ä¸åŒç›®å½•ï¼‰
        for f in os.listdir(img_dir):
            if Path(f).suffix.lower() in img_exts:
                total_images += 1
                label_path = Path(label_dir) / (Path(f).stem + '.txt')
                
                if label_path.exists():
                    labeled_images += 1
                    boxes_in_image = 0
                    
                    try:
                        with open(label_path, 'r') as file:
                            for line in file:
                                parts = line.strip().split()
                                if len(parts) >= 5:
                                    class_id = int(float(parts[0]))
                                    boxes_in_image += 1
                                    total_boxes += 1
                                    class_counts[class_id] = class_counts.get(class_id, 0) + 1
                    except:
                        continue
                    
                    box_counts_per_image.append(boxes_in_image)
    
    return total_images, labeled_images, total_boxes, class_counts


def create_basic_stats_table(all_stats):
    """åˆ›å»ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯è¡¨æ ¼"""
    table = PrettyTable()
    table.field_names = ["æ•°æ®é›†", "æ€»å›¾ç‰‡æ•°", "æœ‰æ ‡æ³¨å›¾ç‰‡æ•°", "èƒŒæ™¯å›¾ç‰‡æ•°", "æ ‡æ³¨æ¡†æ€»æ•°", "å¹³å‡æ¡†æ•°/å›¾"]
    
    total_images = 0
    total_labeled = 0
    total_boxes = 0
    
    for split_name, stats in all_stats.items():
        imgs, labeled, boxes, _ = stats
        background = imgs - labeled
        avg_boxes = boxes / labeled if labeled > 0 else 0
        
        table.add_row([
            split_name,
            imgs,
            labeled,
            background,
            boxes,
            f"{avg_boxes:.2f}"
        ])
        
        total_images += imgs
        total_labeled += labeled
        total_boxes += boxes
    
    # æ·»åŠ æ€»è®¡è¡Œ
    total_background = total_images - total_labeled
    total_avg_boxes = total_boxes / total_labeled if total_labeled > 0 else 0
    table.add_row([
        "æ€»è®¡",
        total_images,
        total_labeled,
        total_background,
        total_boxes,
        f"{total_avg_boxes:.2f}"
    ])
    
    print(f"\nğŸ“Š æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:")
    print(table)


def create_class_distribution_table(all_stats, class_names):
    """åˆ›å»ºç±»åˆ«åˆ†å¸ƒè¡¨æ ¼"""
    # æ”¶é›†æ‰€æœ‰ç±»åˆ«ID
    all_class_ids = set()
    for stats in all_stats.values():
        all_class_ids.update(stats[3].keys())
    
    if not all_class_ids:
        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç±»åˆ«æ ‡æ³¨")
        return
    
    all_class_ids = sorted(all_class_ids)
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    split_totals = {}
    grand_total = 0
    for split_name, stats in all_stats.items():
        split_total = sum(stats[3].values())
        split_totals[split_name] = split_total
        grand_total += split_total
    
    # åˆ›å»ºè¡¨æ ¼
    table = PrettyTable()
    header = ["ç±»åˆ«ID", "ç±»åˆ«åç§°"]
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ†å‰²æ·»åŠ åˆ—
    for split_name in all_stats.keys():
        header.append(f"{split_name}(æ•°é‡(ç™¾åˆ†æ¯”))")
    
    header.append("æ€»æ•°(ç™¾åˆ†æ¯”)")
    table.field_names = header
    
    # æ·»åŠ æ¯ä¸ªç±»åˆ«çš„æ•°æ®
    for class_id in all_class_ids:
        class_name = class_names.get(class_id, f"Class_{class_id}") if class_names else f"Class_{class_id}"
        row = [class_id, class_name]
        
        class_total = 0
        for split_name, stats in all_stats.items():
            count = stats[3].get(class_id, 0)
            percentage = (count / split_totals[split_name]) * 100 if split_totals[split_name] > 0 else 0
            row.append(f"{count}({percentage:.1f}%)")
            class_total += count
        
        # æ€»è®¡åˆ—
        total_percentage = (class_total / grand_total) * 100 if grand_total > 0 else 0
        row.append(f"{class_total}({total_percentage:.1f}%)")
        
        table.add_row(row)
    
    # æ·»åŠ æ€»è®¡è¡Œ
    total_row = ["", "æ€»è®¡"]
    for split_name in all_stats.keys():
        total_count = split_totals[split_name]
        total_row.append(f"{total_count}(100.0%)")
    total_row.append(f"{grand_total}(100.0%)")
    table.add_row(total_row)
    
    print(f"\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡è¡¨:")
    print(table)


def analyze_dataset(dataset_dir, show_stats=False):
    """åˆ†ææ•´ä¸ªæ•°æ®é›†"""
    print(f"ğŸ” å¼€å§‹åˆ†ææ•°æ®é›†: {dataset_dir}")
    
    # æ£€æµ‹æ•°æ®é›†ç»“æ„
    structure, paths = get_dataset_paths(dataset_dir)
    
    if not paths:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æœ‰æ•ˆçš„YOLOæ•°æ®é›†ç»“æ„")
        print("æ”¯æŒçš„ç»“æ„:")
        print("  1. æ ¼å¼ä¸€: dataset/train/images/ + dataset/train/labels/ ç­‰")
        print("  2. æ ¼å¼äºŒ: dataset/images/train/ + dataset/labels/train/ ç­‰")
        print("  3. ç®€å•ç»“æ„: dataset/images/ + dataset/labels/")
        print("  4. æ··åˆç»“æ„: å›¾ç‰‡å’Œtxtæ ‡ç­¾æ–‡ä»¶åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­")
        return
    
    # åŠ è½½ç±»åˆ«åç§°
    class_names = load_class_names(dataset_dir)
    
    # è¾“å‡ºç»“æ„ç±»å‹ä¿¡æ¯
    structure_name = {
        'format1': 'æ ¼å¼ä¸€ (æŒ‰æ•°æ®é›†åˆ’åˆ†åˆ†ç»„)',
        'format2': 'æ ¼å¼äºŒ (æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„)',
        'simple': 'ç®€å•ç»“æ„',
        'mixed': 'æ··åˆç»“æ„ (å›¾ç‰‡å’Œæ ‡ç­¾åœ¨åŒä¸€æ–‡ä»¶å¤¹)',
        'unknown': 'æœªçŸ¥æ ¼å¼'
    }.get(structure, 'æœªçŸ¥æ ¼å¼')
    
    print(f"ğŸ“ æ£€æµ‹åˆ°æ•°æ®é›†ç»“æ„: {structure_name}")
    if class_names:
        print(f"ğŸ“‹ åŠ è½½äº† {len(class_names)} ä¸ªç±»åˆ«åç§°")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°ç±»åˆ«åç§°æ–‡ä»¶ (classes.txt æˆ– data.yaml)")
    
    # åˆ†ææ¯ä¸ªæ•°æ®é›†åˆ†å‰²ï¼ˆæ”¶é›†ç»Ÿè®¡ä¿¡æ¯ä½†ä¸æ˜¾ç¤ºæ£€æŸ¥æŠ¥å‘Šï¼‰
    total_missing = 0
    total_redundant = 0
    all_stats = {}
    missing_reports = []
    
    for split_name, img_dir, label_dir in paths:
        # æ£€æŸ¥å¯¹åº”å…³ç³»
        missing, redundant = check_yolo_dataset(img_dir, label_dir)
        missing_reports.append((split_name, missing, redundant))
        
        total_missing += len(missing)
        total_redundant += len(redundant)
        
        # ç»Ÿè®¡åˆ†æ
        if show_stats:
            stats = analyze_annotation_statistics(img_dir, label_dir, split_name, class_names)
            all_stats[split_name] = stats
    
    # è¾“å‡ºé¡ºåºï¼š1. ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡è¡¨ï¼ˆå¦‚æœæœ‰ç»Ÿè®¡ï¼‰
    if show_stats and all_stats:
        create_class_distribution_table(all_stats, class_names)
        
        # 2. æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        create_basic_stats_table(all_stats)
    
    # 3. æ€»ä½“æ‘˜è¦
    print(f"\n{'='*30} æ€»ä½“æ‘˜è¦ {'='*30}")
    print(f"ğŸ“Š æ•°æ®é›†åˆ†å‰²æ•°: {len(paths)}")
    print(f"âš ï¸  æ€»ç¼ºå¤±æ ‡æ³¨: {total_missing}")
    print(f"âš ï¸  æ€»å†—ä½™æ ‡æ³¨: {total_redundant}")
    
    # 4. æ£€æŸ¥æŠ¥å‘Šï¼ˆæœ€åæ˜¾ç¤ºï¼‰
    for split_name, missing, redundant in missing_reports:
        generate_report(split_name, missing, redundant)


def main():
    parser = argparse.ArgumentParser(description="YOLOæ•°æ®é›†åˆ†æå·¥å…· - æ”¯æŒå¤šç§æ•°æ®é›†ç»“æ„")
    parser.add_argument('--dataset_dir', '-d', required=True, 
                       help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--stats', '-s', action='store_true', 
                       help='æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.dataset_dir):
        print(f"âŒ é”™è¯¯: æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {args.dataset_dir}")
        return
    
    analyze_dataset(args.dataset_dir, args.stats)


if __name__ == "__main__":
    main()