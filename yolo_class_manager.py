import os
import shutil
import argparse
from collections import defaultdict
from datetime import datetime
from utils.logging_utils import tee_stdout_stderr
_LOG_FILE = tee_stdout_stderr('logs')
from utils.yolo_utils import (
    detect_yolo_structure,
    yolo_label_dirs,
    iter_label_files,
    list_possible_class_files,
    read_class_names,
    write_class_names,
    get_folder_size,
)




def analyze_dataset_classes(base_dir):
    """åˆ†ææ•°æ®é›†ä¸­çš„ç±»åˆ«ä½¿ç”¨æƒ…å†µ"""
    structure, _, _ = detect_yolo_structure(base_dir)
    
    if structure == 'unknown':
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®é›†ç»“æ„")
        return None, None
    
    print(f"ğŸ“ æ£€æµ‹åˆ°æ•°æ®é›†ç»“æ„: {structure}")
    
    # è·å–æ‰€æœ‰æ ‡ç­¾ç›®å½•
    label_dirs = yolo_label_dirs(base_dir, structure)
    
    # ç»Ÿè®¡ç±»åˆ«ä½¿ç”¨æƒ…å†µ
    class_usage = defaultdict(int)  # {class_id: count}
    total_annotations = 0
    
    for labels_dir in label_dirs:
        for label_file in iter_label_files(labels_dir, structure):
            label_path = os.path.join(labels_dir, label_file)
            try:
                with open(label_path, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line:
                            class_id = int(line.split()[0])
                            class_usage[class_id] += 1
                            total_annotations += 1
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è¯»å–æ ‡ç­¾æ–‡ä»¶ {label_path}: {e}")
    
    # æŸ¥æ‰¾ç±»åˆ«æ–‡ä»¶
    class_files = list_possible_class_files(base_dir)
    class_names = []
    
    if class_files:
        class_file_path = os.path.join(base_dir, class_files[0])
        class_names = read_class_names(class_file_path)
        print(f"ğŸ“‹ æ‰¾åˆ°ç±»åˆ«æ–‡ä»¶: {class_files[0]}")
    
    return class_usage, class_names


def delete_classes(base_dir, class_ids_to_delete, backup=True):
    """åˆ é™¤æŒ‡å®šçš„ç±»åˆ«"""
    print(f"\nå¼€å§‹åˆ é™¤ç±»åˆ«: {class_ids_to_delete}")
    
    # åˆ†æå½“å‰æ•°æ®é›†
    class_usage, class_names = analyze_dataset_classes(base_dir)
    if class_usage is None:
        return False
    
    # éªŒè¯è¦åˆ é™¤çš„ç±»åˆ«æ˜¯å¦åœ¨ç±»åˆ«æ–‡ä»¶ä¸­å®šä¹‰
    all_defined_classes = set(range(len(class_names))) if class_names else set()
    used_classes = set(class_usage.keys())
    
    # æ£€æŸ¥è¦åˆ é™¤çš„ç±»åˆ«æ˜¯å¦åœ¨å®šä¹‰èŒƒå›´å†…
    invalid_classes = set(class_ids_to_delete) - all_defined_classes
    if invalid_classes:
        print(f"é”™è¯¯: ä»¥ä¸‹ç±»åˆ«è¶…å‡ºå®šä¹‰èŒƒå›´ (0-{len(class_names)-1}): {invalid_classes}")
        return False
    
    # åˆ†ç±»ï¼šå·²ä½¿ç”¨çš„ç±»åˆ«å’Œæœªä½¿ç”¨çš„ç±»åˆ«
    used_classes_to_delete = set(class_ids_to_delete) & used_classes
    unused_classes_to_delete = set(class_ids_to_delete) - used_classes
    
    print(f"è¦åˆ é™¤çš„å·²ä½¿ç”¨ç±»åˆ«: {used_classes_to_delete}")
    print(f"è¦åˆ é™¤çš„æœªä½¿ç”¨ç±»åˆ«: {unused_classes_to_delete}")
    
    if not class_ids_to_delete:
        print("æ²¡æœ‰æœ‰æ•ˆçš„ç±»åˆ«éœ€è¦åˆ é™¤")
        return False
    
    # åˆ›å»ºå¤‡ä»½
    if backup:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"{base_dir}_backup_before_delete_{timestamp}"
        if os.path.exists(backup_dir):
            shutil.rmtree(backup_dir)
        shutil.copytree(base_dir, backup_dir)
        print(f"âœ“ å·²åˆ›å»ºå¤‡ä»½: {backup_dir}")
    
    structure, _, _ = detect_yolo_structure(base_dir)
    label_dirs = yolo_label_dirs(base_dir, structure)
    
    # æ‰€æœ‰è¦åˆ é™¤çš„ç±»åˆ«
    all_classes_to_delete = set(class_ids_to_delete)
    
    # åˆ›å»ºç±»åˆ«æ˜ å°„ (åˆ é™¤åé‡æ–°ç¼–å·)
    remaining_classes = sorted([c for c in used_classes if c not in all_classes_to_delete])
    class_mapping = {old_id: new_id for new_id, old_id in enumerate(remaining_classes)}
    
    deleted_annotations = 0
    updated_files = 0
    
    # å¤„ç†æ¯ä¸ªæ ‡ç­¾ç›®å½• (åªå¤„ç†å·²ä½¿ç”¨çš„ç±»åˆ«)
    for labels_dir in label_dirs:
        for label_file in iter_label_files(labels_dir, structure):
            label_path = os.path.join(labels_dir, label_file)
            updated_lines = []
            file_changed = False
            
            try:
                with open(label_path, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line:
                            parts = line.split()
                            class_id = int(parts[0])
                            
                            if class_id in all_classes_to_delete:
                                # åˆ é™¤è¿™ä¸ªæ ‡æ³¨
                                deleted_annotations += 1
                                file_changed = True
                            else:
                                # é‡æ–°æ˜ å°„ç±»åˆ«ID
                                new_class_id = class_mapping[class_id]
                                parts[0] = str(new_class_id)
                                updated_lines.append(' '.join(parts))
                                if new_class_id != class_id:
                                    file_changed = True
                
                if file_changed:
                    with open(label_path, 'w') as f:
                        for line in updated_lines:
                            f.write(line + '\n')
                    updated_files += 1
                    
            except Exception as e:
                print(f"é”™è¯¯: æ— æ³•å¤„ç†æ ‡ç­¾æ–‡ä»¶ {label_path}: {e}")
    
    # æ›´æ–°ç±»åˆ«æ–‡ä»¶ (åˆ é™¤æ‰€æœ‰æŒ‡å®šçš„ç±»åˆ«ï¼ŒåŒ…æ‹¬æœªä½¿ç”¨çš„)
    class_files = list_possible_class_files(base_dir)
    if class_files and class_names:
        # åˆ›å»ºæ–°çš„ç±»åˆ«åç§°åˆ—è¡¨ï¼Œæ’é™¤æ‰€æœ‰è¦åˆ é™¤çš„ç±»åˆ«
        remaining_class_indices = [i for i in range(len(class_names)) if i not in all_classes_to_delete]
        updated_class_names = [class_names[i] for i in remaining_class_indices]
        
        for class_file in class_files:
            class_file_path = os.path.join(base_dir, class_file)
            write_class_names(class_file_path, updated_class_names)
            print(f"âœ“ å·²æ›´æ–°ç±»åˆ«æ–‡ä»¶: {class_file}")
    
    print(f"\nåˆ é™¤æ“ä½œå®Œæˆ:")
    print(f"åˆ é™¤çš„ç±»åˆ«: {all_classes_to_delete}")
    print(f"åˆ é™¤çš„æ ‡æ³¨æ•°é‡: {deleted_annotations}")
    print(f"æ›´æ–°çš„æ–‡ä»¶æ•°é‡: {updated_files}")
    print(f"å‰©ä½™ç±»åˆ«æ•°é‡: {len(class_names) - len(all_classes_to_delete) if class_names else 0}")
    
    return True


def rename_classes(base_dir, class_renames, backup=True):
    """é‡å‘½åç±»åˆ« (åªæ›´æ–°ç±»åˆ«æ–‡ä»¶ä¸­çš„åç§°ï¼Œä¸æ”¹å˜æ ‡ç­¾æ–‡ä»¶ä¸­çš„ID)"""
    print(f"\nå¼€å§‹é‡å‘½åç±»åˆ«: {class_renames}")
    
    # æŸ¥æ‰¾ç±»åˆ«æ–‡ä»¶
    class_files = list_possible_class_files(base_dir)
    if not class_files:
        print("é”™è¯¯: æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶")
        return False
    
    # åˆ›å»ºå¤‡ä»½
    if backup:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"{base_dir}_backup_before_rename_{timestamp}"
        if os.path.exists(backup_dir):
            shutil.rmtree(backup_dir)
        shutil.copytree(base_dir, backup_dir)
        print(f"âœ“ å·²åˆ›å»ºå¤‡ä»½: {backup_dir}")
    
    # è¯»å–ç°æœ‰ç±»åˆ«åç§°
    class_file_path = os.path.join(base_dir, class_files[0])
    class_names = read_class_names(class_file_path)
    
    if not class_names:
        print("é”™è¯¯: æ— æ³•è¯»å–ç±»åˆ«åç§°")
        return False
    
    print(f"åŸå§‹ç±»åˆ«: {class_names}")
    
    # åº”ç”¨é‡å‘½å
    updated_class_names = class_names.copy()
    for old_name, new_name in class_renames.items():
        if old_name in updated_class_names:
            index = updated_class_names.index(old_name)
            updated_class_names[index] = new_name
            print(f"âœ“ é‡å‘½å: {old_name} -> {new_name}")
        else:
            print(f"è­¦å‘Š: ç±»åˆ« '{old_name}' ä¸å­˜åœ¨")
    
    # æ›´æ–°æ‰€æœ‰ç±»åˆ«æ–‡ä»¶
    for class_file in class_files:
        class_file_path = os.path.join(base_dir, class_file)
        write_class_names(class_file_path, updated_class_names)
        print(f"âœ“ å·²æ›´æ–°ç±»åˆ«æ–‡ä»¶: {class_file}")
    
    print(f"æ›´æ–°åç±»åˆ«: {updated_class_names}")
    print("é‡å‘½åæ“ä½œå®Œæˆ!")
    
    return True


def cleanup_backups(base_dir, keep_count=5, dry_run=False):
    """æ¸…ç†æ—§çš„å¤‡ä»½æ–‡ä»¶å¤¹"""
    import glob
    import re
    
    print(f"\nğŸ§¹ æ¸…ç†å¤‡ä»½æ–‡ä»¶å¤¹...")
    
    # æŸ¥æ‰¾æ‰€æœ‰å¤‡ä»½æ–‡ä»¶å¤¹
    backup_pattern = f"{base_dir}_backup_*"
    backup_dirs = glob.glob(backup_pattern)
    
    if not backup_dirs:
        print("æœªæ‰¾åˆ°ä»»ä½•å¤‡ä»½æ–‡ä»¶å¤¹")
        return
    
    # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæå–æ—¶é—´æˆ³éƒ¨åˆ†ï¼‰
    def extract_timestamp(path):
        # åŒ¹é…æ—¶é—´æˆ³æ ¼å¼ YYYYMMDD_HHMMSS
        match = re.search(r'_(\d{8}_\d{6})$', path)
        return match.group(1) if match else '00000000_000000'
    
    backup_dirs.sort(key=extract_timestamp, reverse=True)
    
    print(f"æ‰¾åˆ° {len(backup_dirs)} ä¸ªå¤‡ä»½æ–‡ä»¶å¤¹:")
    for i, backup_dir in enumerate(backup_dirs):
        timestamp = extract_timestamp(backup_dir)
    size = get_folder_size(backup_dir)
    status = "ä¿ç•™" if i < keep_count else "åˆ é™¤"
    print(f"  {i+1}. {os.path.basename(backup_dir)} (æ—¶é—´: {timestamp}, å¤§å°: {size:.1f}MB) - {status}")
    
    # åˆ é™¤è¶…å‡ºä¿ç•™æ•°é‡çš„å¤‡ä»½
    to_delete = backup_dirs[keep_count:]
    
    if not to_delete:
        print(f"âœ“ æ‰€æœ‰å¤‡ä»½éƒ½åœ¨ä¿ç•™èŒƒå›´å†… (ä¿ç•™æœ€æ–° {keep_count} ä¸ª)")
        return
    
    if dry_run:
        print(f"\n[æ¼”ä¹ æ¨¡å¼] å°†è¦åˆ é™¤ {len(to_delete)} ä¸ªæ—§å¤‡ä»½:")
        for backup_dir in to_delete:
            print(f"  - {backup_dir}")
        print("ä½¿ç”¨ --execute å‚æ•°æ‰§è¡Œå®é™…åˆ é™¤")
        return
    
    print(f"\nå¼€å§‹åˆ é™¤ {len(to_delete)} ä¸ªæ—§å¤‡ä»½...")
    deleted_count = 0
    total_size_freed = 0
    
    for backup_dir in to_delete:
        try:
            size = get_folder_size(backup_dir)
            shutil.rmtree(backup_dir)
            print(f"âœ“ å·²åˆ é™¤: {backup_dir}")
            deleted_count += 1
            total_size_freed += size
        except Exception as e:
            print(f"âœ— åˆ é™¤å¤±è´¥: {backup_dir} - {e}")
    
    print(f"\næ¸…ç†å®Œæˆ:")
    print(f"åˆ é™¤äº† {deleted_count} ä¸ªå¤‡ä»½æ–‡ä»¶å¤¹")
    print(f"é‡Šæ”¾ç©ºé—´: {total_size_freed:.1f}MB")
    print(f"ä¿ç•™æœ€æ–° {len(backup_dirs) - deleted_count} ä¸ªå¤‡ä»½")


def show_dataset_info(base_dir):
    """æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯"""
    print(f"\nğŸ“Š æ•°æ®é›†ä¿¡æ¯åˆ†æ: {base_dir}")
    print("=" * 50)
    
    # åˆ†ææ•°æ®é›†
    class_usage, class_names = analyze_dataset_classes(base_dir)
    if class_usage is None:
        return
    
    # æ˜¾ç¤ºç±»åˆ«ä¿¡æ¯
    print(f"ğŸ“‹ ç±»åˆ«å®šä¹‰ (å…± {len(class_names)} ä¸ª):")
    for i, name in enumerate(class_names):
        usage_count = class_usage.get(i, 0)
        print(f"  {i}: {name} (ä½¿ç”¨ {usage_count} æ¬¡)")
    
    # æ˜¾ç¤ºä½¿ç”¨ç»Ÿè®¡
    print(f"\nğŸ“ˆ ç±»åˆ«ä½¿ç”¨ç»Ÿè®¡:")
    total_annotations = sum(class_usage.values())
    print(f"æ€»æ ‡æ³¨æ•°é‡: {total_annotations}")
    
    if class_usage:
        used_classes = len(class_usage)
        unused_classes = [i for i in range(len(class_names)) if i not in class_usage]
        
        print(f"å·²ä½¿ç”¨ç±»åˆ«: {used_classes}")
        if unused_classes:
            print(f"æœªä½¿ç”¨ç±»åˆ«: {unused_classes}")
            print(f"æœªä½¿ç”¨ç±»åˆ«åç§°: {[class_names[i] for i in unused_classes if i < len(class_names)]}")
        
        # æ˜¾ç¤ºä½¿ç”¨é¢‘ç‡æ’åº
        sorted_usage = sorted(class_usage.items(), key=lambda x: x[1], reverse=True)
        print(f"\nä½¿ç”¨é¢‘ç‡æ’åº:")
        for class_id, count in sorted_usage:
            class_name = class_names[class_id] if class_id < len(class_names) else f"æœªçŸ¥ç±»åˆ«{class_id}"
            percentage = count / total_annotations * 100
            print(f"  ç±»åˆ« {class_id} ({class_name}): {count} æ¬¡ ({percentage:.1f}%)")


def _images_dir_for_labels(base_dir: str, labels_dir: str, structure: str) -> str:
    """æ ¹æ®ç»“æ„æ¨å¯¼ä¸ labels_dir å¯¹åº”çš„ images ç›®å½•ã€‚"""
    if structure == 'standard':
        return os.path.join(base_dir, 'images')
    if structure == 'format1':
        # base/train/labels -> base/train/images
        parent = os.path.dirname(labels_dir)  # .../train
        return os.path.join(parent, 'images')
    if structure == 'format2':
        # base/labels/split -> base/images/split
        split = os.path.basename(labels_dir)
        return os.path.join(base_dir, 'images', split)
    # mixed: ä¸æ ‡ç­¾åŒç›®å½•
    return labels_dir


def _find_image_path(images_dir: str, stem: str) -> str | None:
    from utils.yolo_utils import IMG_EXTS
    for ext in IMG_EXTS:
        p = os.path.join(images_dir, stem + ext)
        if os.path.exists(p):
            return p
    return None


def _load_class_names_from_dataset(base_dir: str) -> list[str]:
    files = list_possible_class_files(base_dir)
    if not files:
        return []
    return read_class_names(os.path.join(base_dir, files[0]))


def _display_class_distribution(class_usage: dict[int, int], class_names: list[str]) -> None:
    total = sum(class_usage.values()) or 1
    print("\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:")
    for cid, cnt in sorted(class_usage.items(), key=lambda x: x[1], reverse=True):
        name = class_names[cid] if cid < len(class_names) else f"Class_{cid}"
        pct = cnt * 100.0 / total
        print(f"  {cid}: {name} -> {cnt} ({pct:.1f}%)")


def _determine_classes_to_remove_by_strategy(strategy: dict, class_usage: dict[int, int]) -> list[int]:
    if not strategy:
        return []
    total = sum(class_usage.values())
    keys = set(class_usage.keys())
    t = strategy.get('type')
    if t == 'min_samples':
        thr = int(strategy['min_samples'])
        return [cid for cid, cnt in class_usage.items() if cnt < thr]
    if t == 'min_percentage':
        thr = float(strategy['min_percentage'])
        min_cnt = total * thr / 100.0
        return [cid for cid, cnt in class_usage.items() if cnt < min_cnt]
    if t == 'keep':
        keep = set(strategy['keep'])
        return [cid for cid in keys if cid not in keep]
    if t == 'remove':
        return list(set(strategy['remove']))
    if t == 'top_n':
        n = int(strategy['top_n'])
        sorted_c = sorted(class_usage.items(), key=lambda x: x[1], reverse=True)
        keep = {cid for cid, _ in sorted_c[:n]}
        return [cid for cid in keys if cid not in keep]
    if t == 'id_range':
        lo, hi = strategy['id_range']
        return [cid for cid in keys if lo <= cid <= hi]
    if t == 'combo':
        ms = int(strategy['min_samples'])
        mp = float(strategy['min_percentage'])
        min_cnt = total * mp / 100.0
        return [cid for cid, cnt in class_usage.items() if cnt < ms or cnt < min_cnt]
    return []


def _interactive_clean_strategy(class_usage: dict[int, int], class_names: list[str]) -> dict | None:
    print("\n====== é€‰æ‹©æ¸…ç†ç­–ç•¥ ======")
    print("1. æŒ‰æœ€å°æ ·æœ¬æ•°æ¸…ç† (åˆ é™¤æ ·æœ¬æ•°å°‘äºé˜ˆå€¼çš„ç±»åˆ«)")
    print("2. æŒ‰ç™¾åˆ†æ¯”æ¸…ç† (åˆ é™¤å æ¯”å°‘äºé˜ˆå€¼çš„ç±»åˆ«)")
    print("3. æ‰‹åŠ¨é€‰æ‹©è¦ä¿ç•™çš„ç±»åˆ«")
    print("4. æ‰‹åŠ¨é€‰æ‹©è¦åˆ é™¤çš„ç±»åˆ«")
    print("5. è‡ªå®šä¹‰æ¸…ç†è§„åˆ™")
    print("0. å–æ¶ˆ")
    while True:
        try:
            ch = input("è¯·è¾“å…¥é€‰æ‹© (0-5): ").strip()
        except KeyboardInterrupt:
            return None
        if ch in {'0', '1', '2', '3', '4', '5'}:
            break
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
    if ch == '0':
        return None
    if ch == '1':
        v = int(input("æœ€å°æ ·æœ¬æ•°é˜ˆå€¼: ").strip())
        return {'type': 'min_samples', 'min_samples': v}
    if ch == '2':
        v = float(input("æœ€å°ç™¾åˆ†æ¯”é˜ˆå€¼(å¦‚ 1.0): ").strip())
        return {'type': 'min_percentage', 'min_percentage': v}
    if ch == '3':
        print("å½“å‰ç±»åˆ«:")
        for cid in sorted(class_usage.keys()):
            name = class_names[cid] if cid < len(class_names) else f"Class_{cid}"
            print(f"  {cid}: {name} ({class_usage[cid]})")
        s = input("è¾“å…¥è¦ä¿ç•™çš„ç±»åˆ«ID(é€—å·åˆ†éš”): ").strip()
        keep = [int(x) for x in s.split(',') if x.strip()]
        return {'type': 'keep', 'keep': keep}
    if ch == '4':
        print("å½“å‰ç±»åˆ«:")
        for cid in sorted(class_usage.keys()):
            name = class_names[cid] if cid < len(class_names) else f"Class_{cid}"
            print(f"  {cid}: {name} ({class_usage[cid]})")
        s = input("è¾“å…¥è¦åˆ é™¤çš„ç±»åˆ«ID(é€—å·åˆ†éš”): ").strip()
        rem = [int(x) for x in s.split(',') if x.strip()]
        return {'type': 'remove', 'remove': rem}
    if ch == '5':
        print("1. ç»„åˆæ¡ä»¶ (æœ€å°æ ·æœ¬æ•° AND æœ€å°ç™¾åˆ†æ¯”)")
        print("2. ä¿ç•™å‰Nä¸ªæœ€å¤šæ ·æœ¬çš„ç±»åˆ«")
        print("3. åˆ é™¤ç‰¹å®šIDèŒƒå›´")
        sc = input("é€‰æ‹©(1-3): ").strip()
        if sc == '1':
            ms = int(input("æœ€å°æ ·æœ¬æ•°: ").strip())
            mp = float(input("æœ€å°ç™¾åˆ†æ¯”: ").strip())
            return {'type': 'combo', 'min_samples': ms, 'min_percentage': mp}
        if sc == '2':
            n = int(input("ä¿ç•™å‰Nä¸ª: ").strip())
            return {'type': 'top_n', 'top_n': n}
        if sc == '3':
            lo = int(input("æœ€å°ID: ").strip())
            hi = int(input("æœ€å¤§ID: ").strip())
            return {'type': 'id_range', 'id_range': (lo, hi)}
    return None


def _generate_clean_report(base_dir: str, class_usage: dict[int, int], class_names: list[str], strategy: dict,
                           classes_removed: list[int], removed_files: list[str], updated_files: list[str]) -> str:
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    report = os.path.join(base_dir, f"cleaning_report_{ts}.md")
    total_ann = sum(class_usage.values()) or 1
    with open(report, 'w', encoding='utf-8') as f:
        f.write("# YOLOæ•°æ®é›†æ¸…ç†æŠ¥å‘Š\n\n")
        f.write(f"**æ¸…ç†æ—¥æœŸ**: {ts}\n")
        f.write(f"**æ•°æ®é›†è·¯å¾„**: `{base_dir}`\n\n")
        f.write("## æ¸…ç†å‰ç»Ÿè®¡\n\n")
        f.write(f"- **æ€»æ ‡æ³¨æ•°**: {total_ann}\n")
        f.write(f"- **ç±»åˆ«æ•°**: {len(class_usage)}\n\n")
        f.write("### åŸå§‹ç±»åˆ«åˆ†å¸ƒ\n\n")
        f.write("| ç±»åˆ«ID | ç±»åˆ«åç§° | æ ‡æ³¨æ•° | å æ¯” |\n")
        f.write("|--------|----------|--------|------|\n")
        for cid, cnt in sorted(class_usage.items()):
            name = class_names[cid] if cid < len(class_names) else f"Class_{cid}"
            pct = cnt * 100.0 / total_ann
            f.write(f"| {cid} | {name} | {cnt} | {pct:.1f}% |\n")
        f.write("\n## æ¸…ç†ç­–ç•¥\n\n")
        f.write(f"{strategy}\n")
        if classes_removed:
            f.write("\n## æ¸…ç†ç»“æœ\n\n")
            f.write(f"- **åˆ é™¤ç±»åˆ«æ•°**: {len(classes_removed)}\n")
            f.write(f"- **åˆ é™¤æ–‡ä»¶æ•°**: {len(removed_files)}\n")
            f.write(f"- **æ›´æ–°æ–‡ä»¶æ•°**: {len(updated_files)}\n")
    print(f"ğŸ“‹ ç”Ÿæˆæ¸…ç†æŠ¥å‘Š: {report}")
    return report


def clean_dataset(base_dir: str, *,
                  min_samples: int | None = None,
                  min_percentage: float | None = None,
                  keep_classes: list[int] | None = None,
                  remove_classes: list[int] | None = None,
                  top_n: int | None = None,
                  id_range: tuple[int, int] | None = None,
                  interactive: bool = False,
                  class_file: str | None = None,
                  backup: bool = True,
                  dry_run: bool = True,
                  assume_yes: bool = False) -> bool:
    """èåˆæ¸…ç†åŠŸèƒ½ï¼šæ”¯æŒå¤šç­–ç•¥åˆ é™¤ç±»åˆ«å¹¶é‡æ˜ å°„IDï¼ŒåŒæ—¶åˆ é™¤æ— æ ‡æ³¨å›¾ç‰‡ï¼Œæ›´æ–°ç±»åä¸YAMLï¼Œå¹¶ç”ŸæˆæŠ¥å‘Šã€‚"""
    # ç»Ÿè®¡
    class_usage, ds_class_names = analyze_dataset_classes(base_dir)
    if class_usage is None:
        return False
    if class_file and os.path.exists(class_file):
        override = read_class_names(class_file)
        if override:
            ds_class_names = override
    print("\nğŸ” æ•°æ®é›†åˆ†æå®Œæˆ")
    _display_class_distribution(class_usage, ds_class_names)

    # è§£æç­–ç•¥
    strategy: dict | None = None
    if interactive or all(v is None for v in [min_samples, min_percentage, keep_classes, remove_classes, top_n, id_range]):
        strategy = _interactive_clean_strategy(class_usage, ds_class_names)
        if strategy is None:
            print("å·²å–æ¶ˆ")
            return False
    else:
        if min_samples is not None:
            strategy = {'type': 'min_samples', 'min_samples': min_samples}
        elif min_percentage is not None:
            strategy = {'type': 'min_percentage', 'min_percentage': min_percentage}
        elif keep_classes is not None:
            strategy = {'type': 'keep', 'keep': keep_classes}
        elif remove_classes is not None:
            strategy = {'type': 'remove', 'remove': remove_classes}
        elif top_n is not None:
            strategy = {'type': 'top_n', 'top_n': top_n}
        elif id_range is not None:
            strategy = {'type': 'id_range', 'id_range': id_range}

    classes_to_remove = _determine_classes_to_remove_by_strategy(strategy, class_usage)
    if not classes_to_remove:
        print("âœ… æ²¡æœ‰éœ€è¦åˆ é™¤çš„ç±»åˆ«")
        return True

    total = sum(class_usage.values()) or 1
    removed_samples = sum(class_usage.get(cid, 0) for cid in classes_to_remove)
    kept_classes = sorted([cid for cid in class_usage.keys() if cid not in set(classes_to_remove)])
    kept_samples = total - removed_samples

    print("\n====== æ¸…ç†é¢„è§ˆ ======")
    print(f"âŒ å°†åˆ é™¤çš„ç±»åˆ«({len(classes_to_remove)}): {sorted(classes_to_remove)}  å…± {removed_samples} ä¸ªæ ‡æ³¨({removed_samples*100.0/total:.1f}%)")
    print(f"âœ… å°†ä¿ç•™çš„ç±»åˆ«({len(kept_classes)}): {kept_classes}  å…± {kept_samples} ä¸ªæ ‡æ³¨({kept_samples*100.0/total:.1f}%)")

    if dry_run:
        print("\n[é¢„è§ˆæ¨¡å¼] æœªè¿›è¡Œå®é™…å†™å…¥ã€‚ä½¿ç”¨ --execute æ‰§è¡Œã€‚")
        return True

    if not assume_yes:
        ans = input("æ˜¯å¦ç¡®è®¤æ‰§è¡Œæ¸…ç†? (y/n): ").strip().lower()
        if ans not in {'y', 'yes'}:
            print("å·²å–æ¶ˆ")
            return False

    # å¤‡ä»½
    if backup:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"{base_dir}_backup_before_clean_{timestamp}"
        if os.path.exists(backup_dir):
            shutil.rmtree(backup_dir)
        shutil.copytree(base_dir, backup_dir)
        print(f"âœ“ å·²åˆ›å»ºå¤‡ä»½: {backup_dir}")

    structure, _, _ = detect_yolo_structure(base_dir)
    label_dirs = yolo_label_dirs(base_dir, structure)

    # æ„å»ºæ˜ å°„
    id_mapping = {old_id: new_id for new_id, old_id in enumerate(kept_classes)}

    removed_files: list[str] = []
    updated_files: list[str] = []

    for labels_dir in label_dirs:
        images_dir = _images_dir_for_labels(base_dir, labels_dir, structure)
        for label_file in iter_label_files(labels_dir, structure):
            label_path = os.path.join(labels_dir, label_file)
            try:
                new_lines = []
                with open(label_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        s = line.strip()
                        if not s:
                            continue
                        parts = s.split()
                        if len(parts) < 5:
                            continue
                        try:
                            cid = int(float(parts[0]))
                        except Exception:
                            continue
                        if cid in classes_to_remove:
                            continue
                        parts[0] = str(id_mapping[cid])
                        new_lines.append(' '.join(parts))

                if not new_lines:
                    # åˆ é™¤æ ‡ç­¾æ–‡ä»¶å’Œå¯¹åº”å›¾ç‰‡
                    try:
                        os.remove(label_path)
                        removed_files.append(label_path)
                    except Exception:
                        pass
                    stem = os.path.splitext(os.path.basename(label_path))[0]
                    img_path = _find_image_path(images_dir, stem)
                    if img_path and os.path.exists(img_path):
                        try:
                            os.remove(img_path)
                            removed_files.append(img_path)
                        except Exception:
                            pass
                else:
                    with open(label_path, 'w', encoding='utf-8') as f:
                        for ln in new_lines:
                            f.write(ln + '\n')
                    updated_files.append(label_path)
            except Exception as e:
                print(f"é”™è¯¯: æ— æ³•å¤„ç†æ ‡ç­¾æ–‡ä»¶ {label_path}: {e}")

    # æ›´æ–°ç±»åˆ«/é…ç½®æ–‡ä»¶
    new_names: list[str] = []
    if ds_class_names:
        for new_id in range(len(kept_classes)):
            old_id = kept_classes[new_id]
            name = ds_class_names[old_id] if old_id < len(ds_class_names) else f"Class_{old_id}"
            new_names.append(name)
    else:
        new_names = [f"Class_{i}" for i in range(len(kept_classes))]

    class_files = list_possible_class_files(base_dir)
    for cf in class_files:
        try:
            write_class_names(os.path.join(base_dir, cf), new_names)
            print(f"âœ“ å·²æ›´æ–°ç±»åˆ«/é…ç½®æ–‡ä»¶: {cf}")
        except Exception as e:
            print(f"è­¦å‘Š: æ›´æ–° {cf} å¤±è´¥: {e}")

    # æŠ¥å‘Š
    _generate_clean_report(base_dir, class_usage, ds_class_names, strategy, classes_to_remove, removed_files, updated_files)

    print("\nğŸ“Š æ¸…ç†å®Œæˆ")
    print(f"  ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶æ•°: {len(removed_files)}")
    print(f"  âœï¸ æ›´æ–°æ–‡ä»¶æ•°: {len(updated_files)}")
    return True


def reindex_classes(base_dir, target_class_names, strict=False, backup=True, dry_run=True, require_same_set=False):
    """æ ¹æ®ç›®æ ‡ç±»åˆ«é¡ºåºé‡æ’æ•°æ®é›†ä¸­æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶çš„ç±»åˆ«IDï¼Œå¹¶æ›´æ–°ç±»åˆ«æ–‡ä»¶ã€‚

    å‚æ•°:
    - base_dir: æ•°æ®é›†æ ¹ç›®å½•
    - target_class_names: ç›®æ ‡ç±»åˆ«é¡ºåº(list[str])ï¼Œå†™å…¥ç±»åˆ«æ–‡ä»¶å¹¶ä½œä¸ºæ–°IDæ˜ å°„ä¾æ®
    - strict: è‹¥ä¸ºTrueï¼Œé‡åˆ°æ—§ç±»åˆ«åœ¨ç›®æ ‡è¡¨ä¸­ä¸å­˜åœ¨åˆ™æŠ¥é”™ç»ˆæ­¢ï¼›å¦åˆ™è·³è¿‡è¯¥æ ‡æ³¨
    - backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
    - dry_run: æ¼”ä¹ æ¨¡å¼ï¼Œä»…ç»Ÿè®¡ä¸é¢„è§ˆï¼Œä¸å®é™…æ”¹å†™
    """
    # è¯»å–å½“å‰ç±»åˆ«
    class_files = list_possible_class_files(base_dir)
    if not class_files:
        print("é”™è¯¯: æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶ï¼Œæ— æ³•è¿›è¡Œé‡æ’")
        return False
    current_class_file = os.path.join(base_dir, class_files[0])
    current_names = read_class_names(current_class_file)
    if not current_names:
        print("é”™è¯¯: æ— æ³•è¯»å–å½“å‰ç±»åˆ«åç§°")
        return False

    print("å½“å‰ç±»åˆ«é¡ºåº:", current_names)
    print("ç›®æ ‡ç±»åˆ«é¡ºåº:", target_class_names)

    if require_same_set:
        cur_set = set(current_names)
        tgt_set = set(target_class_names)
        if cur_set != tgt_set:
            only_in_cur = sorted(list(cur_set - tgt_set))
            only_in_tgt = sorted(list(tgt_set - cur_set))
            print("é”™è¯¯: ç±»åˆ«é›†åˆä¸ä¸€è‡´ï¼Œå·²å¯ç”¨ --require-same-setï¼š")
            if only_in_cur:
                print(f"  ä»…åœ¨å½“å‰é›†åˆä¸­å­˜åœ¨: {only_in_cur}")
            if only_in_tgt:
                print(f"  ä»…åœ¨ç›®æ ‡é›†åˆä¸­å­˜åœ¨: {only_in_tgt}")
            return False

    # æ„å»ºæ˜ å°„: æ—§class_id -> æ–°class_id
    name_to_new = {n: i for i, n in enumerate(target_class_names)}
    missing_old = [n for n in current_names if n not in name_to_new]
    if missing_old:
        msg = f"è­¦å‘Š: ä»¥ä¸‹æ—§ç±»åˆ«åœ¨ç›®æ ‡åˆ—è¡¨ä¸­ä¸å­˜åœ¨: {missing_old}"
        if strict:
            print("é”™è¯¯(ä¸¥æ ¼æ¨¡å¼):", msg)
            return False
        else:
            print(msg + "ï¼Œè¿™äº›ç±»åˆ«çš„æ ‡æ³¨å°†è¢«ä¸¢å¼ƒ")

    old_to_new = {}
    for old_id, name in enumerate(current_names):
        if name in name_to_new:
            old_to_new[old_id] = name_to_new[name]
        else:
            old_to_new[old_id] = None  # ä¸¢å¼ƒ

    # åˆ›å»ºå¤‡ä»½
    if backup and not dry_run:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"{base_dir}_backup_before_reindex_{timestamp}"
        if os.path.exists(backup_dir):
            shutil.rmtree(backup_dir)
        shutil.copytree(base_dir, backup_dir)
        print(f"âœ“ å·²åˆ›å»ºå¤‡ä»½: {backup_dir}")

    structure, _, _ = detect_yolo_structure(base_dir)
    label_dirs = yolo_label_dirs(base_dir, structure)

    updated_files = 0
    dropped_annotations = 0
    total_annotations = 0

    for labels_dir in label_dirs:
        for label_file in iter_label_files(labels_dir, structure):
            label_path = os.path.join(labels_dir, label_file)
            try:
                new_lines = []
                with open(label_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        s = line.strip()
                        if not s:
                            continue
                        parts = s.split()
                        try:
                            old_id = int(parts[0])
                        except Exception:
                            continue
                        total_annotations += 1
                        new_id = old_to_new.get(old_id, None)
                        if new_id is None:
                            dropped_annotations += 1
                            continue
                        parts[0] = str(new_id)
                        new_lines.append(' '.join(parts))

                if not dry_run:
                    with open(label_path, 'w', encoding='utf-8') as f:
                        for ln in new_lines:
                            f.write(ln + '\n')
                updated_files += 1
            except Exception as e:
                print(f"é”™è¯¯: æ— æ³•å¤„ç†æ ‡ç­¾æ–‡ä»¶ {label_path}: {e}")

    # æ›´æ–°ç±»åˆ«æ–‡ä»¶
    if not dry_run:
        for class_file in class_files:
            class_file_path = os.path.join(base_dir, class_file)
            write_class_names(class_file_path, target_class_names)
            print(f"âœ“ å·²æ›´æ–°ç±»åˆ«æ–‡ä»¶: {class_file}")

    print("\né‡æ’å®Œæˆ(é¢„è§ˆ)" if dry_run else "\né‡æ’å®Œæˆ")
    print(f"å¤„ç†çš„æ ‡ç­¾æ–‡ä»¶: {updated_files}")
    print(f"æ€»æ ‡æ³¨: {total_annotations}")
    if missing_old:
        print(f"ä¸¢å¼ƒçš„æ ‡æ³¨(å› ç±»åˆ«ç¼ºå¤±): {dropped_annotations}")
    return True


def main():
    parser = argparse.ArgumentParser(description="YOLOæ•°æ®é›†ç±»åˆ«ç®¡ç†å·¥å…·")
    parser.add_argument("--dataset_dir", "-d", required=True,
                       help="æ•°æ®é›†ç›®å½•è·¯å¾„")
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ä¿¡æ¯å‘½ä»¤
    info_parser = subparsers.add_parser('info', help='æ˜¾ç¤ºæ•°æ®é›†ç±»åˆ«ä¿¡æ¯')
    
    # åˆ é™¤å‘½ä»¤
    delete_parser = subparsers.add_parser('delete', help='åˆ é™¤æŒ‡å®šç±»åˆ«')
    delete_parser.add_argument("--class_ids", "-c", nargs='+', type=int, required=True,
                              help="è¦åˆ é™¤çš„ç±»åˆ«IDåˆ—è¡¨")
    delete_parser.add_argument("--no-backup", action="store_true",
                              help="ä¸åˆ›å»ºå¤‡ä»½")
    
    # é‡å‘½åå‘½ä»¤
    rename_parser = subparsers.add_parser('rename', help='é‡å‘½åç±»åˆ«')
    rename_parser.add_argument("--renames", "-r", nargs='+', required=True,
                              help="é‡å‘½åæ˜ å°„ï¼Œæ ¼å¼: old_name1:new_name1 old_name2:new_name2")
    rename_parser.add_argument("--no-backup", action="store_true",
                              help="ä¸åˆ›å»ºå¤‡ä»½")
    
    # å¤‡ä»½æ¸…ç†å‘½ä»¤
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ—§çš„å¤‡ä»½æ–‡ä»¶å¤¹')
    cleanup_parser.add_argument("--keep", type=int, default=5,
                               help="ä¿ç•™æœ€æ–°çš„å¤‡ä»½æ•°é‡ (é»˜è®¤: 5)")
    cleanup_parser.add_argument("--dry-run", action="store_true",
                               help="æ¼”ä¹ æ¨¡å¼ï¼Œåªæ˜¾ç¤ºå°†è¦åˆ é™¤çš„å¤‡ä»½ï¼Œä¸æ‰§è¡Œå®é™…åˆ é™¤")
    cleanup_parser.add_argument("--execute", action="store_true",
                               help="æ‰§è¡Œå®é™…åˆ é™¤æ“ä½œ")

    # é‡æ’å‘½ä»¤
    reindex_parser = subparsers.add_parser('reindex', help='æ ¹æ®ç›®æ ‡ç±»åˆ«é¡ºåºé‡æ’æ‰€æœ‰æ ‡ç­¾ä¸­çš„ç±»åˆ«IDï¼Œå¹¶æ›´æ–°ç±»åˆ«æ–‡ä»¶')
    reindex_group = reindex_parser.add_mutually_exclusive_group(required=True)
    reindex_group.add_argument("--to-file", dest="to_file", help="ç›®æ ‡ç±»åˆ«æ–‡ä»¶è·¯å¾„ (classes.txt æˆ– *.yaml)ï¼Œå…¶é¡ºåºå°†ä½œä¸ºæ–°ç±»åˆ«é¡ºåº")
    reindex_group.add_argument("--to-classes", dest="to_classes", nargs='+', help="ç›´æ¥æä¾›ç›®æ ‡ç±»åˆ«é¡ºåºåˆ—è¡¨ï¼Œä¾‹å¦‚: --to-classes arco_0 arco_1 arco_2 ...")
    reindex_parser.add_argument("--strict", action="store_true", help="ä¸¥æ ¼æ¨¡å¼: æ—§ç±»åˆ«è‹¥ä¸åœ¨ç›®æ ‡åˆ—è¡¨ä¸­åˆ™æŠ¥é”™ç»ˆæ­¢")
    reindex_parser.add_argument("--require-same-set", action="store_true", help="å¼ºåˆ¶è¦æ±‚å½“å‰ä¸ç›®æ ‡ç±»åˆ«é›†åˆå®Œå…¨ä¸€è‡´ï¼Œå¦åˆ™ä¸­æ­¢")
    reindex_parser.add_argument("--no-backup", action="store_true", help="ä¸åˆ›å»ºå¤‡ä»½")
    reindex_parser.add_argument("--dry-run", action="store_true", help="æ¼”ä¹ æ¨¡å¼ï¼Œä»…é¢„è§ˆæ›´æ”¹ï¼Œä¸å†™å›ç£ç›˜ (é»˜è®¤: é¢„è§ˆ)")
    reindex_parser.add_argument("--execute", action="store_true", help="æ‰§è¡Œå®é™…é‡æ’(ä¸ --dry-run äº’æ–¥)")

    # æ¸…ç†å‘½ä»¤ï¼ˆèåˆ yolo_label_cleaner åŠŸèƒ½ï¼‰
    clean_parser = subparsers.add_parser('clean', help='æŒ‰ç­–ç•¥æ¸…ç†ç±»åˆ«ä¸æ ·æœ¬ï¼Œé‡æ˜ å°„IDï¼Œåˆ é™¤æ— æ ‡æ³¨å›¾ç‰‡ï¼Œå¹¶æ›´æ–°ç±»å/YAML/æŠ¥å‘Š')
    strategy_group = clean_parser.add_mutually_exclusive_group(required=False)
    strategy_group.add_argument("--min-samples", type=int, help="åˆ é™¤æ ·æœ¬æ•°å°‘äºé˜ˆå€¼çš„ç±»åˆ«")
    strategy_group.add_argument("--min-percentage", type=float, help="åˆ é™¤å æ¯”å°‘äºé˜ˆå€¼(%)çš„ç±»åˆ«")
    clean_parser.add_argument("--keep-classes", nargs='+', type=int, help="æ‰‹åŠ¨æŒ‡å®šä¿ç•™çš„ç±»åˆ«IDåˆ—è¡¨")
    clean_parser.add_argument("--remove-classes", nargs='+', type=int, help="æ‰‹åŠ¨æŒ‡å®šåˆ é™¤çš„ç±»åˆ«IDåˆ—è¡¨")
    clean_parser.add_argument("--top-n", type=int, help="ä»…ä¿ç•™å‰Nä¸ªæœ€å¤šæ ·æœ¬çš„ç±»åˆ«")
    clean_parser.add_argument("--remove-id-range", nargs=2, type=int, metavar=('MIN', 'MAX'), help="åˆ é™¤ç‰¹å®šIDèŒƒå›´çš„ç±»åˆ«")
    clean_parser.add_argument("--interactive", action="store_true", help="äº¤äº’å¼é€‰æ‹©ç­–ç•¥")
    clean_parser.add_argument("--class-file", help="æŒ‡å®šå¤–éƒ¨ç±»åˆ«æ–‡ä»¶ç”¨äºåç§°æ˜ å°„(å¯é€‰)")
    clean_parser.add_argument("--no-backup", action="store_true", help="ä¸åˆ›å»ºå¤‡ä»½")
    clean_parser.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼(é»˜è®¤é¢„è§ˆï¼Œä½¿ç”¨ --execute æ‰§è¡Œ)")
    clean_parser.add_argument("--execute", action="store_true", help="æ‰§è¡Œå®é™…æ¸…ç†")
    clean_parser.add_argument("--yes", action="store_true", help="æ— éœ€ç¡®è®¤ç›´æ¥æ‰§è¡Œ")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # éªŒè¯æ•°æ®é›†ç›®å½•
    if not os.path.exists(args.dataset_dir):
        print(f"é”™è¯¯: æ•°æ®é›†ç›®å½• {args.dataset_dir} ä¸å­˜åœ¨")
        return
    
    if args.command == 'info':
        show_dataset_info(args.dataset_dir)
    
    elif args.command == 'delete':
        backup = not args.no_backup
        delete_classes(args.dataset_dir, args.class_ids, backup)
    
    elif args.command == 'rename':
        backup = not args.no_backup
        
        # è§£æé‡å‘½åæ˜ å°„
        class_renames = {}
        for rename_pair in args.renames:
            try:
                old_name, new_name = rename_pair.split(':', 1)
                class_renames[old_name] = new_name
            except ValueError:
                print(f"é”™è¯¯: æ— æ•ˆçš„é‡å‘½åæ ¼å¼ '{rename_pair}'ï¼Œåº”ä¸º 'old_name:new_name'")
                return
        
        rename_classes(args.dataset_dir, class_renames, backup)
    
    elif args.command == 'cleanup':
        if args.dry_run and args.execute:
            print("é”™è¯¯: --dry-run å’Œ --execute ä¸èƒ½åŒæ—¶ä½¿ç”¨")
            return
        
        dry_run = args.dry_run or not args.execute
        cleanup_backups(args.dataset_dir, args.keep, dry_run)

    elif args.command == 'reindex':
        if args.dry_run and args.execute:
            print("é”™è¯¯: --dry-run å’Œ --execute ä¸èƒ½åŒæ—¶ä½¿ç”¨")
            return
        dry_run = args.dry_run or not args.execute
        backup = not args.no_backup

        # è¯»å–ç›®æ ‡ç±»åˆ«
        if args.to_file:
            if not os.path.exists(args.to_file):
                print(f"é”™è¯¯: ç›®æ ‡ç±»åˆ«æ–‡ä»¶ä¸å­˜åœ¨: {args.to_file}")
                return
            target_names = read_class_names(args.to_file)
        else:
            target_names = args.to_classes or []

        if not target_names:
            print("é”™è¯¯: ç›®æ ‡ç±»åˆ«åˆ—è¡¨ä¸ºç©º")
            return

        reindex_classes(
            args.dataset_dir,
            target_names,
            strict=args.strict,
            backup=backup,
            dry_run=dry_run,
            require_same_set=args.require_same_set,
        )

    elif args.command == 'clean':
        if args.dry_run and args.execute:
            print("é”™è¯¯: --dry-run å’Œ --execute ä¸èƒ½åŒæ—¶ä½¿ç”¨")
            return
        dry_run = args.dry_run or not args.execute
        backup = not args.no_backup
        id_range = tuple(args.remove_id_range) if args.remove_id_range else None
        clean_dataset(
            args.dataset_dir,
            min_samples=args.min_samples,
            min_percentage=args.min_percentage,
            keep_classes=args.keep_classes,
            remove_classes=args.remove_classes,
            top_n=args.top_n,
            id_range=id_range,
            interactive=args.interactive,
            class_file=args.class_file,
            backup=backup,
            dry_run=dry_run,
            assume_yes=args.yes,
        )


if __name__ == "__main__":
    main()
