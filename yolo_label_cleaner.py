#!/usr/bin/env python3

import os
import shutil
import json
from pathlib import Path
import argparse
from collections import Counter, defaultdict
import yaml
from utils.logging_utils import tee_stdout_stderr
_LOG_FILE = tee_stdout_stderr('logs')

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class YOLODatasetCleaner:
    """YOLOæ•°æ®é›†æ¸…ç†å™¨"""
    
    def __init__(self, dataset_path, backup=True, verbose=True):
        """
        åˆå§‹åŒ–æ¸…ç†å™¨
        
        Args:
            dataset_path: æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„
            backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        self.dataset_path = Path(dataset_path)
        self.backup = backup
        self.verbose = verbose
        self.splits = ['train', 'val', 'test']  # æ”¯æŒçš„æ•°æ®é›†åˆ’åˆ†
        self.img_exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.class_counts = defaultdict(int)
        self.total_annotations = 0
        self.total_images = 0
        
        # æ£€æµ‹æ•°æ®é›†æ ¼å¼
        self.dataset_format = self.detect_dataset_format()
    
    def detect_dataset_format(self):
        """
        æ£€æµ‹YOLOæ•°æ®é›†æ ¼å¼
        è¿”å›: 1 ä¸ºæ ¼å¼ä¸€, 2 ä¸ºæ ¼å¼äºŒ
        """
        # æ£€æŸ¥æ ¼å¼ä¸€: dataset/train/images/, dataset/train/labels/
        format1_exists = any((self.dataset_path / split / 'images').exists() and 
                           (self.dataset_path / split / 'labels').exists() 
                           for split in self.splits)
        
        # æ£€æŸ¥æ ¼å¼äºŒ: dataset/images/train/, dataset/labels/train/
        format2_exists = ((self.dataset_path / 'images').exists() and 
                         (self.dataset_path / 'labels').exists() and
                         any((self.dataset_path / 'images' / split).exists() for split in self.splits))
        
        if format1_exists and not format2_exists:
            self.log("ğŸ” æ£€æµ‹åˆ°æ ¼å¼ä¸€: train/images/, train/labels/")
            return 1
        elif format2_exists and not format1_exists:
            self.log("ğŸ” æ£€æµ‹åˆ°æ ¼å¼äºŒ: images/train/, labels/train/")
            return 2
        elif format1_exists and format2_exists:
            self.log("âš ï¸  æ£€æµ‹åˆ°æ··åˆæ ¼å¼ï¼Œä¼˜å…ˆä½¿ç”¨æ ¼å¼ä¸€")
            return 1
        else:
            self.log("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„YOLOæ•°æ®é›†æ ¼å¼")
            return None
    
    def get_split_paths(self, split):
        """æ ¹æ®æ•°æ®é›†æ ¼å¼è·å–åˆ†å‰²çš„è·¯å¾„"""
        if self.dataset_format == 1:
            # æ ¼å¼ä¸€: dataset/train/images/, dataset/train/labels/
            images_dir = self.dataset_path / split / 'images'
            labels_dir = self.dataset_path / split / 'labels'
        else:
            # æ ¼å¼äºŒ: dataset/images/train/, dataset/labels/train/
            images_dir = self.dataset_path / 'images' / split
            labels_dir = self.dataset_path / 'labels' / split
        
        return images_dir, labels_dir
        
    def log(self, message):
        """è¾“å‡ºæ—¥å¿—ä¿¡æ¯"""
        if self.verbose:
            print(message)
    
    def load_class_names(self):
        """åŠ è½½ç±»åˆ«åç§°"""
        class_names = {}
        
        # å°è¯•ä¸åŒçš„ç±»åˆ«æ–‡ä»¶å
        possible_files = ["classes.txt", "names.txt", "class.names", "labels.txt"]
        
        for filename in possible_files:
            class_file = self.dataset_path / filename
            if class_file.exists():
                try:
                    with open(class_file, 'r', encoding='utf-8') as f:
                        for idx, line in enumerate(f):
                            class_name = line.strip()
                            if class_name:
                                class_names[idx] = class_name
                    self.log(f"ğŸ“‚ åŠ è½½ç±»åˆ«æ–‡ä»¶: {class_file}")
                    return class_names
                except Exception as e:
                    self.log(f"âš ï¸  è¯»å–ç±»åˆ«æ–‡ä»¶å¤±è´¥: {e}")
        
        self.log("âš ï¸  æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç±»åˆ«ID")
        return {}
    
    def analyze_dataset(self):
        """åˆ†ææ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒ"""
        self.log("ğŸ” åˆ†ææ•°æ®é›†...")
        
        if self.dataset_format is None:
            self.log("âŒ æ— æ³•åˆ†ææ•°æ®é›†ï¼šæœªæ£€æµ‹åˆ°æœ‰æ•ˆæ ¼å¼")
            return {}
        
        split_stats = {}
        
        for split in self.splits:
            images_dir, labels_dir = self.get_split_paths(split)
            
            if not labels_dir.exists():
                self.log(f"âš ï¸  è·³è¿‡ä¸å­˜åœ¨çš„ç›®å½•: {labels_dir}")
                continue
            
            split_class_counts = defaultdict(int)
            split_images = 0
            split_annotations = 0
            
            # åˆ†ææ ‡ç­¾æ–‡ä»¶
            for label_file in labels_dir.glob('*.txt'):
                split_images += 1
                try:
                    with open(label_file, 'r') as f:
                        for line in f:
                            parts = line.strip().split()
                            if len(parts) >= 5:
                                class_id = int(float(parts[0]))
                                split_class_counts[class_id] += 1
                                self.class_counts[class_id] += 1
                                split_annotations += 1
                                self.total_annotations += 1
                except Exception as e:
                    self.log(f"âŒ è¯»å–æ ‡ç­¾æ–‡ä»¶å¤±è´¥: {label_file}, é”™è¯¯: {e}")
            
            self.total_images += split_images
            split_stats[split] = {
                'images': split_images,
                'annotations': split_annotations,
                'class_counts': dict(split_class_counts)
            }
        
        return split_stats
    
    def display_analysis(self, split_stats, class_names):
        """æ˜¾ç¤ºåˆ†æç»“æœ"""
        self.log(f"\n{'='*60}")
        self.log(f"{'æ•°æ®é›†åˆ†ææŠ¥å‘Š':^56}")
        self.log(f"{'='*60}")
        
        # æ€»ä½“ç»Ÿè®¡
        self.log(f"ğŸ“Š æ€»å›¾ç‰‡æ•°: {self.total_images}")
        self.log(f"ğŸ“Š æ€»æ ‡æ³¨æ•°: {self.total_annotations}")
        self.log(f"ğŸ“Š ç±»åˆ«æ•°: {len(self.class_counts)}")
        
        # å„splitç»Ÿè®¡
        for split, stats in split_stats.items():
            if stats['images'] > 0:
                self.log(f"\nğŸ“‚ {split.upper()} é›†:")
                self.log(f"   å›¾ç‰‡æ•°: {stats['images']}")
                self.log(f"   æ ‡æ³¨æ•°: {stats['annotations']}")
        
        # ç±»åˆ«åˆ†å¸ƒ
        self.log(f"\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:")
        sorted_classes = sorted(self.class_counts.items(), key=lambda x: x[1], reverse=True)
        
        for class_id, count in sorted_classes:
            class_name = class_names.get(class_id, f"Class_{class_id}")
            percentage = (count / self.total_annotations) * 100 if self.total_annotations > 0 else 0
            self.log(f"   ç±»åˆ« {class_id} ({class_name}): {count} ä¸ª ({percentage:.1f}%)")
    
    def get_cleaning_strategy(self, class_names):
        """è·å–ç”¨æˆ·çš„æ¸…ç†ç­–ç•¥"""
        self.log(f"\n{'='*60}")
        self.log(f"{'é€‰æ‹©æ¸…ç†ç­–ç•¥':^56}")
        self.log(f"{'='*60}")
        
        print("è¯·é€‰æ‹©æ¸…ç†ç­–ç•¥:")
        print("1. æŒ‰æœ€å°æ ·æœ¬æ•°æ¸…ç† (åˆ é™¤æ ·æœ¬æ•°å°‘äºé˜ˆå€¼çš„ç±»åˆ«)")
        print("2. æŒ‰ç™¾åˆ†æ¯”æ¸…ç† (åˆ é™¤å æ¯”å°‘äºé˜ˆå€¼çš„ç±»åˆ«)")
        print("3. æ‰‹åŠ¨é€‰æ‹©è¦ä¿ç•™çš„ç±»åˆ«")
        print("4. æ‰‹åŠ¨é€‰æ‹©è¦åˆ é™¤çš„ç±»åˆ«")
        print("5. è‡ªå®šä¹‰æ¸…ç†è§„åˆ™")
        print("0. å–æ¶ˆæ¸…ç†")
        
        while True:
            try:
                choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-5): ").strip()
                if choice in ['0', '1', '2', '3', '4', '5']:
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-5")
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return None
        
        if choice == '0':
            return None
        
        strategy = {'type': choice}
        
        if choice == '1':
            # æŒ‰æœ€å°æ ·æœ¬æ•°æ¸…ç†
            while True:
                try:
                    min_samples = int(input("è¯·è¾“å…¥æœ€å°æ ·æœ¬æ•°é˜ˆå€¼: "))
                    strategy['min_samples'] = min_samples
                    break
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•´æ•°")
        
        elif choice == '2':
            # æŒ‰ç™¾åˆ†æ¯”æ¸…ç†
            while True:
                try:
                    min_percentage = float(input("è¯·è¾“å…¥æœ€å°ç™¾åˆ†æ¯”é˜ˆå€¼ (ä¾‹å¦‚: 1.0 è¡¨ç¤º1%): "))
                    strategy['min_percentage'] = min_percentage
                    break
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        elif choice == '3':
            # æ‰‹åŠ¨é€‰æ‹©ä¿ç•™çš„ç±»åˆ«
            print(f"\nå½“å‰ç±»åˆ«åˆ—è¡¨:")
            for class_id, count in sorted(self.class_counts.items()):
                class_name = class_names.get(class_id, f"Class_{class_id}")
                print(f"  {class_id}: {class_name} ({count} ä¸ªæ ·æœ¬)")
            
            while True:
                try:
                    keep_input = input("è¯·è¾“å…¥è¦ä¿ç•™çš„ç±»åˆ«ID (ç”¨é€—å·åˆ†éš”): ").strip()
                    keep_classes = [int(x.strip()) for x in keep_input.split(',') if x.strip()]
                    
                    # éªŒè¯ç±»åˆ«ID
                    invalid_ids = [cid for cid in keep_classes if cid not in self.class_counts]
                    if invalid_ids:
                        print(f"âŒ æ— æ•ˆçš„ç±»åˆ«ID: {invalid_ids}")
                        continue
                    
                    strategy['keep_classes'] = keep_classes
                    break
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ç±»åˆ«ID")
        
        elif choice == '4':
            # æ‰‹åŠ¨é€‰æ‹©åˆ é™¤çš„ç±»åˆ«
            print(f"\nå½“å‰ç±»åˆ«åˆ—è¡¨:")
            for class_id, count in sorted(self.class_counts.items()):
                class_name = class_names.get(class_id, f"Class_{class_id}")
                print(f"  {class_id}: {class_name} ({count} ä¸ªæ ·æœ¬)")
            
            while True:
                try:
                    remove_input = input("è¯·è¾“å…¥è¦åˆ é™¤çš„ç±»åˆ«ID (ç”¨é€—å·åˆ†éš”): ").strip()
                    remove_classes = [int(x.strip()) for x in remove_input.split(',') if x.strip()]
                    
                    # éªŒè¯ç±»åˆ«ID
                    invalid_ids = [cid for cid in remove_classes if cid not in self.class_counts]
                    if invalid_ids:
                        print(f"âŒ æ— æ•ˆçš„ç±»åˆ«ID: {invalid_ids}")
                        continue
                    
                    strategy['remove_classes'] = remove_classes
                    break
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ç±»åˆ«ID")
        
        elif choice == '5':
            # è‡ªå®šä¹‰æ¸…ç†è§„åˆ™
            print("\nè‡ªå®šä¹‰æ¸…ç†è§„åˆ™:")
            print("1. ç»„åˆæ¡ä»¶ (æœ€å°æ ·æœ¬æ•° AND æœ€å°ç™¾åˆ†æ¯”)")
            print("2. ä¿ç•™å‰Nä¸ªæœ€å¤šæ ·æœ¬çš„ç±»åˆ«")
            print("3. åˆ é™¤ç‰¹å®šèŒƒå›´çš„ç±»åˆ«")
            
            sub_choice = input("è¯·é€‰æ‹©è‡ªå®šä¹‰è§„åˆ™ (1-3): ").strip()
            strategy['custom_type'] = sub_choice
            
            if sub_choice == '1':
                min_samples = int(input("è¯·è¾“å…¥æœ€å°æ ·æœ¬æ•°: "))
                min_percentage = float(input("è¯·è¾“å…¥æœ€å°ç™¾åˆ†æ¯”: "))
                strategy['min_samples'] = min_samples
                strategy['min_percentage'] = min_percentage
            
            elif sub_choice == '2':
                top_n = int(input("è¯·è¾“å…¥è¦ä¿ç•™çš„ç±»åˆ«æ•°é‡: "))
                strategy['top_n'] = top_n
            
            elif sub_choice == '3':
                min_id = int(input("è¯·è¾“å…¥è¦åˆ é™¤çš„ç±»åˆ«IDæœ€å°å€¼: "))
                max_id = int(input("è¯·è¾“å…¥è¦åˆ é™¤çš„ç±»åˆ«IDæœ€å¤§å€¼: "))
                strategy['id_range'] = (min_id, max_id)
        
        return strategy
    
    def determine_classes_to_remove(self, strategy, class_names):
        """æ ¹æ®ç­–ç•¥ç¡®å®šè¦åˆ é™¤çš„ç±»åˆ«"""
        if not strategy:
            return []
        
        classes_to_remove = []
        
        if strategy['type'] == '1':
            # æŒ‰æœ€å°æ ·æœ¬æ•°
            min_samples = strategy['min_samples']
            classes_to_remove = [class_id for class_id, count in self.class_counts.items() 
                               if count < min_samples]
        
        elif strategy['type'] == '2':
            # æŒ‰ç™¾åˆ†æ¯”
            min_percentage = strategy['min_percentage']
            min_count = (min_percentage / 100.0) * self.total_annotations
            classes_to_remove = [class_id for class_id, count in self.class_counts.items() 
                               if count < min_count]
        
        elif strategy['type'] == '3':
            # æ‰‹åŠ¨é€‰æ‹©ä¿ç•™
            keep_classes = strategy['keep_classes']
            classes_to_remove = [class_id for class_id in self.class_counts.keys() 
                               if class_id not in keep_classes]
        
        elif strategy['type'] == '4':
            # æ‰‹åŠ¨é€‰æ‹©åˆ é™¤
            classes_to_remove = strategy['remove_classes']
        
        elif strategy['type'] == '5':
            # è‡ªå®šä¹‰è§„åˆ™
            custom_type = strategy['custom_type']
            
            if custom_type == '1':
                # ç»„åˆæ¡ä»¶
                min_samples = strategy['min_samples']
                min_percentage = strategy['min_percentage']
                min_count = (min_percentage / 100.0) * self.total_annotations
                classes_to_remove = [class_id for class_id, count in self.class_counts.items() 
                                   if count < min_samples or count < min_count]
            
            elif custom_type == '2':
                # ä¿ç•™å‰Nä¸ª
                top_n = strategy['top_n']
                sorted_classes = sorted(self.class_counts.items(), key=lambda x: x[1], reverse=True)
                keep_classes = [class_id for class_id, _ in sorted_classes[:top_n]]
                classes_to_remove = [class_id for class_id in self.class_counts.keys() 
                                   if class_id not in keep_classes]
            
            elif custom_type == '3':
                # IDèŒƒå›´åˆ é™¤
                min_id, max_id = strategy['id_range']
                classes_to_remove = [class_id for class_id in self.class_counts.keys() 
                                   if min_id <= class_id <= max_id]
        
        return classes_to_remove
    
    def preview_cleaning(self, classes_to_remove, class_names):
        """é¢„è§ˆæ¸…ç†ç»“æœ"""
        if not classes_to_remove:
            self.log("âœ… æ²¡æœ‰éœ€è¦åˆ é™¤çš„ç±»åˆ«!")
            return False
        
        classes_to_keep = [class_id for class_id in self.class_counts.keys() 
                          if class_id not in classes_to_remove]
        
        self.log(f"\n{'='*60}")
        self.log(f"{'æ¸…ç†é¢„è§ˆ':^56}")
        self.log(f"{'='*60}")
        
        # è¦åˆ é™¤çš„ç±»åˆ«
        self.log(f"âŒ å°†åˆ é™¤çš„ç±»åˆ« ({len(classes_to_remove)} ä¸ª):")
        removed_samples = 0
        for class_id in sorted(classes_to_remove):
            class_name = class_names.get(class_id, f"Class_{class_id}")
            count = self.class_counts[class_id]
            percentage = (count / self.total_annotations) * 100
            removed_samples += count
            self.log(f"   ç±»åˆ« {class_id} ({class_name}): {count} ä¸ª ({percentage:.1f}%)")
        
        # è¦ä¿ç•™çš„ç±»åˆ«
        self.log(f"\nâœ… å°†ä¿ç•™çš„ç±»åˆ« ({len(classes_to_keep)} ä¸ª):")
        kept_samples = 0
        for class_id in sorted(classes_to_keep):
            class_name = class_names.get(class_id, f"Class_{class_id}")
            count = self.class_counts[class_id]
            percentage = (count / self.total_annotations) * 100
            kept_samples += count
            self.log(f"   ç±»åˆ« {class_id} ({class_name}): {count} ä¸ª ({percentage:.1f}%)")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.log(f"\nğŸ“Š æ¸…ç†ç»Ÿè®¡:")
        self.log(f"   åˆ é™¤æ ·æœ¬æ•°: {removed_samples} ({(removed_samples/self.total_annotations)*100:.1f}%)")
        self.log(f"   ä¿ç•™æ ·æœ¬æ•°: {kept_samples} ({(kept_samples/self.total_annotations)*100:.1f}%)")
        
        # ç”¨æˆ·ç¡®è®¤
        while True:
            confirm = input(f"\næ˜¯å¦ç¡®è®¤æ‰§è¡Œæ¸…ç†? (y/n): ").strip().lower()
            if confirm in ['y', 'yes', 'n', 'no']:
                return confirm in ['y', 'yes']
            print("âŒ è¯·è¾“å…¥ y æˆ– n")
    
    def create_backup(self):
        """åˆ›å»ºæ•°æ®é›†å¤‡ä»½"""
        if not self.backup:
            return None
        
        backup_path = self.dataset_path.parent / f"{self.dataset_path.name}_backup_{self.get_timestamp()}"
        
        if backup_path.exists():
            self.log(f"âš ï¸  å¤‡ä»½ç›®å½•å·²å­˜åœ¨: {backup_path}")
            return backup_path
        
        self.log(f"ğŸ’¾ åˆ›å»ºå¤‡ä»½: {backup_path}")
        try:
            shutil.copytree(self.dataset_path, backup_path)
            self.log(f"âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ")
            return backup_path
        except Exception as e:
            self.log(f"âŒ å¤‡ä»½åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def get_timestamp(self):
        """è·å–æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def clean_dataset(self, classes_to_remove, class_names):
        """æ‰§è¡Œæ•°æ®é›†æ¸…ç†"""
        if not classes_to_remove:
            return
        
        classes_to_keep = [class_id for class_id in self.class_counts.keys() 
                          if class_id not in classes_to_remove]
        
        self.log(f"\nğŸ§¹ å¼€å§‹æ¸…ç†æ•°æ®é›†...")
        
        # åˆ›å»ºç±»åˆ«IDæ˜ å°„
        id_mapping = {old_id: new_id for new_id, old_id in enumerate(sorted(classes_to_keep))}
        
        # ç»Ÿè®¡ä¿¡æ¯
        removed_files = []
        updated_files = []
        
        for split in self.splits:
            images_dir, labels_dir = self.get_split_paths(split)
            
            if not labels_dir.exists():
                continue
            
            self.log(f"ğŸ”§ å¤„ç† {split} é›†...")
            
            for label_file in labels_dir.glob('*.txt'):
                try:
                    # è¯»å–å¹¶è¿‡æ»¤æ ‡ç­¾
                    valid_lines = []
                    with open(label_file, 'r') as f:
                        for line in f:
                            parts = line.strip().split()
                            if len(parts) >= 5:
                                class_id = int(float(parts[0]))
                                if class_id in classes_to_keep:
                                    # é‡æ–°æ˜ å°„ç±»åˆ«ID
                                    new_class_id = id_mapping[class_id]
                                    parts[0] = str(new_class_id)
                                    valid_lines.append(' '.join(parts))
                    
                    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ ‡æ³¨ï¼Œåˆ é™¤æ–‡ä»¶
                    if not valid_lines:
                        # åˆ é™¤æ ‡ç­¾æ–‡ä»¶
                        label_file.unlink()
                        removed_files.append(str(label_file))
                        
                        # åˆ é™¤å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
                        img_stem = label_file.stem
                        for ext in self.img_exts:
                            img_file = images_dir / f"{img_stem}{ext}"
                            if img_file.exists():
                                img_file.unlink()
                                removed_files.append(str(img_file))
                                break
                    else:
                        # æ›´æ–°æ ‡ç­¾æ–‡ä»¶
                        with open(label_file, 'w') as f:
                            f.write('\n'.join(valid_lines) + '\n')
                        updated_files.append(str(label_file))
                
                except Exception as e:
                    self.log(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {label_file}, é”™è¯¯: {e}")
        
        # æ›´æ–°é…ç½®æ–‡ä»¶
        self.update_config_files(classes_to_keep, class_names, id_mapping)
        
        # æ˜¾ç¤ºç»“æœ
        self.log(f"\nğŸ“Š æ¸…ç†å®Œæˆ:")
        self.log(f"   ğŸ—‘ï¸  åˆ é™¤æ–‡ä»¶æ•°: {len(removed_files)}")
        self.log(f"   âœï¸  æ›´æ–°æ–‡ä»¶æ•°: {len(updated_files)}")
        
        return {
            'removed_files': removed_files,
            'updated_files': updated_files,
            'id_mapping': id_mapping
        }
    
    def update_config_files(self, classes_to_keep, class_names, id_mapping):
        """æ›´æ–°é…ç½®æ–‡ä»¶"""
        # æ›´æ–°classes.txt
        classes_file = self.dataset_path / 'classes.txt'
        if classes_file.exists() or class_names:
            new_class_names = []
            for new_id in range(len(classes_to_keep)):
                old_id = sorted(classes_to_keep)[new_id]
                class_name = class_names.get(old_id, f"Class_{old_id}")
                new_class_names.append(class_name)
            
            with open(classes_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(new_class_names))
            self.log(f"ğŸ“ æ›´æ–° classes.txt: {new_class_names}")
        
        # æ›´æ–°data.yaml
        data_yaml = self.dataset_path / 'data.yaml'
        if data_yaml.exists():
            try:
                with open(data_yaml, 'r', encoding='utf-8') as f:
                    data = yaml.safe_load(f)
                
                # æ›´æ–°ç±»åˆ«æ•°å’Œåç§°
                data['nc'] = len(classes_to_keep)
                if 'names' in data:
                    new_names = []
                    for new_id in range(len(classes_to_keep)):
                        old_id = sorted(classes_to_keep)[new_id]
                        if isinstance(data['names'], list) and old_id < len(data['names']):
                            new_names.append(data['names'][old_id])
                        else:
                            class_name = class_names.get(old_id, f"Class_{old_id}")
                            new_names.append(class_name)
                    data['names'] = new_names
                
                with open(data_yaml, 'w', encoding='utf-8') as f:
                    yaml.safe_dump(data, f, default_flow_style=False, allow_unicode=True)
                self.log(f"ğŸ“ æ›´æ–° data.yaml")
                
            except Exception as e:
                self.log(f"âš ï¸  æ›´æ–° data.yaml å¤±è´¥: {e}")
    
    def generate_report(self, strategy, classes_removed, cleaning_result, class_names, backup_path):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report_path = self.dataset_path / f"cleaning_report_{self.get_timestamp()}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# YOLOæ•°æ®é›†æ¸…ç†æŠ¥å‘Š\n\n")
            f.write(f"**æ¸…ç†æ—¥æœŸ**: {self.get_timestamp()}\n")
            f.write(f"**æ•°æ®é›†è·¯å¾„**: `{self.dataset_path}`\n")
            if backup_path:
                f.write(f"**å¤‡ä»½è·¯å¾„**: `{backup_path}`\n")
            f.write(f"\n## æ¸…ç†å‰ç»Ÿè®¡\n\n")
            f.write(f"- **æ€»å›¾ç‰‡æ•°**: {self.total_images}\n")
            f.write(f"- **æ€»æ ‡æ³¨æ•°**: {self.total_annotations}\n")
            f.write(f"- **ç±»åˆ«æ•°**: {len(self.class_counts)}\n\n")
            
            f.write(f"### åŸå§‹ç±»åˆ«åˆ†å¸ƒ\n\n")
            f.write("| ç±»åˆ«ID | ç±»åˆ«åç§° | æ ‡æ³¨æ•° | å æ¯” |\n")
            f.write("|--------|----------|--------|------|\n")
            
            for class_id, count in sorted(self.class_counts.items()):
                class_name = class_names.get(class_id, f"Class_{class_id}")
                percentage = (count / self.total_annotations) * 100
                f.write(f"| {class_id} | {class_name} | {count} | {percentage:.1f}% |\n")
            
            f.write(f"\n## æ¸…ç†ç­–ç•¥\n\n")
            f.write(f"**ç­–ç•¥ç±»å‹**: {strategy['type']}\n")
            # æ ¹æ®ç­–ç•¥ç±»å‹æ·»åŠ è¯¦ç»†ä¿¡æ¯
            
            if classes_removed:
                f.write(f"\n## æ¸…ç†ç»“æœ\n\n")
                f.write(f"- **åˆ é™¤ç±»åˆ«æ•°**: {len(classes_removed)}\n")
                f.write(f"- **åˆ é™¤æ–‡ä»¶æ•°**: {len(cleaning_result['removed_files'])}\n")
                f.write(f"- **æ›´æ–°æ–‡ä»¶æ•°**: {len(cleaning_result['updated_files'])}\n")
        
        self.log(f"ğŸ“‹ ç”Ÿæˆæ¸…ç†æŠ¥å‘Š: {report_path}")


def main():
    parser = argparse.ArgumentParser(description="YOLOæ•°æ®é›†æ ‡ç­¾æ¸…ç†å·¥å…·")
    parser.add_argument('dataset_path', help='æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--no-backup', action='store_true', help='ä¸åˆ›å»ºå¤‡ä»½')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼')
    parser.add_argument('--class-file', help='æŒ‡å®šç±»åˆ«åç§°æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--auto-clean', help='è‡ªåŠ¨æ¸…ç†æ¨¡å¼ (min_samples:N æˆ– min_percentage:N)')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.dataset_path):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {args.dataset_path}")
        return
    
    # åˆå§‹åŒ–æ¸…ç†å™¨
    cleaner = YOLODatasetCleaner(
        dataset_path=args.dataset_path,
        backup=not args.no_backup,
        verbose=not args.quiet
    )
    
    try:
        # åŠ è½½ç±»åˆ«åç§°
        if args.class_file:
            class_names = {}
            with open(args.class_file, 'r', encoding='utf-8') as f:
                for idx, line in enumerate(f):
                    class_name = line.strip()
                    if class_name:
                        class_names[idx] = class_name
        else:
            class_names = cleaner.load_class_names()
        
        # åˆ†ææ•°æ®é›†
        split_stats = cleaner.analyze_dataset()
        cleaner.display_analysis(split_stats, class_names)
        
        # è·å–æ¸…ç†ç­–ç•¥
        if args.auto_clean:
            # è‡ªåŠ¨æ¨¡å¼
            if args.auto_clean.startswith('min_samples:'):
                min_samples = int(args.auto_clean.split(':')[1])
                strategy = {'type': '1', 'min_samples': min_samples}
            elif args.auto_clean.startswith('min_percentage:'):
                min_percentage = float(args.auto_clean.split(':')[1])
                strategy = {'type': '2', 'min_percentage': min_percentage}
            else:
                print("âŒ æ— æ•ˆçš„è‡ªåŠ¨æ¸…ç†å‚æ•°")
                return
        else:
            # äº¤äº’æ¨¡å¼
            strategy = cleaner.get_cleaning_strategy(class_names)
        
        if not strategy:
            cleaner.log("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ¸…ç†æ“ä½œ")
            return
        
        # ç¡®å®šè¦åˆ é™¤çš„ç±»åˆ«
        classes_to_remove = cleaner.determine_classes_to_remove(strategy, class_names)
        
        # é¢„è§ˆå¹¶ç¡®è®¤
        if not cleaner.preview_cleaning(classes_to_remove, class_names):
            cleaner.log("ğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ¸…ç†æ“ä½œ")
            return
        
        # åˆ›å»ºå¤‡ä»½
        backup_path = cleaner.create_backup()
        
        # æ‰§è¡Œæ¸…ç†
        cleaning_result = cleaner.clean_dataset(classes_to_remove, class_names)
        
        # ç”ŸæˆæŠ¥å‘Š
        cleaner.generate_report(strategy, classes_to_remove, cleaning_result, class_names, backup_path)
        
        cleaner.log(f"\nğŸ‰ æ•°æ®é›†æ¸…ç†å®Œæˆ!")
        
    except KeyboardInterrupt:
        cleaner.log(f"\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        cleaner.log(f"\nâŒ æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main()
