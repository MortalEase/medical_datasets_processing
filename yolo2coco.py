#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""YOLO -> COCO è½¬æ¢è„šæœ¬

æ ¸å¿ƒ: è‡ªåŠ¨æ£€æµ‹ YOLO 4 ç§ç»“æ„ (format1/format2/standard/mixed) å¹¶è¾“å‡º COCO JSON
æ‰©å±•: å¯¹ standard/mixed å¯é€‰ --split è§¦å‘äºŒæ¬¡åˆ†å±‚åˆ’åˆ† (è°ƒç”¨ coco_dataset_split.py)
é»˜è®¤: æœªæ˜¾å¼æŒ‡å®šè¾“å‡ºç›®å½•æ—¶æŒ‰ç»“æ„ç»™å‡ºåˆç†é»˜è®¤ JSON å­˜æ”¾è·¯å¾„
"""
import os
import cv2
import json
import argparse
import tempfile
import subprocess
from pathlib import Path
from tqdm import tqdm
from utils.logging_utils import tee_stdout_stderr
_LOG_FILE = tee_stdout_stderr('logs')

IMAGE_EXTS = ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp']


def detect_structure(root_dir: str):
    """æ£€æµ‹æ•°æ®é›†ç»“æ„ç±»å‹å¹¶è¿”å›ç»“æ„æ ‡è¯†ä¸å¯éå†çš„ (split, images_dir, labels_dir) åˆ—è¡¨ã€‚

    è¿”å›:
        structure(str): format1 | format2 | standard | mixed | unknown
        paths(list[tuple]): [(split_name, images_dir, labels_dir), ...]
    """
    root = Path(root_dir)

    # ---- æ ¼å¼ä¸€: train/images, train/labels ----
    splits_found = []
    for sp in ['train', 'val', 'test']:
        if (root / sp / 'images').exists() and (root / sp / 'labels').exists():
            splits_found.append(sp)
    if splits_found:
        paths = [(sp, str(root / sp / 'images'), str(root / sp / 'labels')) for sp in splits_found]
        return 'format1', paths

    # ---- æ ¼å¼äºŒ: images/train, labels/train ----
    splits_found = []
    for sp in ['train', 'val', 'test']:
        if (root / 'images' / sp).exists() and (root / 'labels' / sp).exists():
            splits_found.append(sp)
    if splits_found:
        paths = [(sp, str(root / 'images' / sp), str(root / 'labels' / sp)) for sp in splits_found]
        return 'format2', paths

    # ---- æ ‡å‡†ç»“æ„: images + labels ----
    if (root / 'images').exists() and (root / 'labels').exists():
        return 'standard', [('dataset', str(root / 'images'), str(root / 'labels'))]

    # ---- æ··åˆç»“æ„: æ ¹ç›®å½•ä¸‹åŒæ—¶åŒ…å«å›¾ç‰‡ä¸ txt (é classes.txt) ----
    has_img = False
    has_txt = False
    for f in root.iterdir():
        if f.is_file():
            suf = f.suffix.lower()
            if suf in IMAGE_EXTS:
                has_img = True
            if suf == '.txt' and f.name not in ['classes.txt', 'obj.names', 'names.txt']:
                has_txt = True
        if has_img and has_txt:
            return 'mixed', [('dataset', str(root), str(root))]

    return 'unknown', []


def load_classes(root_dir: str):
    """å°è¯•åŠ è½½ç±»åˆ«åç§°(ä¼˜å…ˆ classes.txt)ã€‚å¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚"""
    for name in ['classes.txt', 'obj.names', 'names.txt']:
        fp = Path(root_dir) / name
        if fp.exists():
            with open(fp, 'r', encoding='utf-8') as f:
                return [line.strip() for line in f if line.strip()]
    return []


def iter_images(images_dir: str):
    """éå†å›¾ç‰‡æ–‡ä»¶å(ä¿æŒåŸå§‹é¡ºåº/ç¨³å®šå¯æ’åº)ã€‚"""
    files = [f for f in os.listdir(images_dir) if Path(f).suffix.lower() in IMAGE_EXTS]
    files.sort()
    return files


def build_categories(class_list):
    """æ ¹æ®ç±»åˆ«åç§°åˆ—è¡¨æ„é€  COCO categoriesã€‚è‹¥åˆ—è¡¨ä¸ºç©ºåˆ™è¿”å›ç©ºã€‚"""
    return [{'id': i, 'name': name, 'supercategory': 'object'} for i, name in enumerate(class_list)]


def read_label_file(label_path):
    """è¯»å–å•ä¸ª YOLO æ ‡ç­¾æ–‡ä»¶, è¿”å›æ¯ä¸€è¡Œçš„(list[str])ã€‚å¼‚å¸¸è¿”å›ç©ºã€‚"""
    try:
        with open(label_path, 'r', encoding='utf-8') as f:
            return [ln.strip() for ln in f if ln.strip()]
    except:
        return []


def convert_split(split_name, images_dir, labels_dir, classes):
    """å°†ä¸€ä¸ªåˆ†å‰²(æˆ–æ•´ä¸ªæ•°æ®é›†)è½¬æ¢ä¸º COCO dictã€‚"""
    categories = build_categories(classes)
    coco = {
        'info': {'description': f'YOLO->COCO è½¬æ¢ ({split_name})'},
        'licenses': [],
        'categories': categories,
        'images': [],
        'annotations': []
    }
    class_count = len(categories) if categories else None
    ann_id = 0
    image_files = iter_images(images_dir)
    for img_id, img_name in enumerate(tqdm(image_files, desc=f'è½¬æ¢ {split_name}')):
        img_path = os.path.join(images_dir, img_name)
        img = cv2.imread(img_path)
        if img is None:
            print(f'è­¦å‘Š: æ— æ³•è¯»å–å›¾ç‰‡ {img_path}, è·³è¿‡')
            continue
        h, w = img.shape[:2]
        coco['images'].append({
            'file_name': img_name,
            'id': img_id,
            'width': w,
            'height': h
        })
        # æ ‡ç­¾æ–‡ä»¶è·¯å¾„(æ··åˆç»“æ„æ—¶ labels_dir == images_dir)
        stem = os.path.splitext(img_name)[0]
        label_path = os.path.join(labels_dir, stem + '.txt')
        if not os.path.exists(label_path):
            continue  # æ— æ ‡ç­¾å›¾ç‰‡ä»ä¿ç•™
        lines = read_label_file(label_path)
        for line in lines:
            parts = line.split()
            if len(parts) < 5:
                continue
            try:
                cls_id = int(float(parts[0]))
                if class_count is not None and (cls_id < 0 or cls_id >= class_count):
                    # è‹¥ç±»åˆ«ç´¢å¼•è¶Šç•Œ, ä»å°è¯•æ¥å—, è‡ªåŠ¨æ‰©å±• categories
                    while cls_id >= len(coco['categories']):
                        new_id = len(coco['categories'])
                        coco['categories'].append({'id': new_id, 'name': f'class_{new_id}', 'supercategory': 'object'})
                x, y, bw, bh = map(float, parts[1:5])
            except Exception:
                continue
            # YOLO (cx,cy,w,h) å½’ä¸€åŒ– -> COCO (x,y,width,height)
            x1 = (x - bw / 2.0) * w
            y1 = (y - bh / 2.0) * h
            box_w = max(0.0, bw * w)
            box_h = max(0.0, bh * h)
            coco['annotations'].append({
                'id': ann_id,
                'image_id': img_id,
                'category_id': cls_id,
                'bbox': [x1, y1, box_w, box_h],
                'area': box_w * box_h,
                'iscrowd': 0,
                'segmentation': [[x1, y1, x1 + box_w, y1, x1 + box_w, y1 + box_h, x1, y1 + box_h]]
            })
            ann_id += 1
    return coco


def save_coco(coco_dict, output_path):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(coco_dict, f, ensure_ascii=False)
    print(f'âœ… ä¿å­˜: {output_path}')


def maybe_split(temp_dir, output_dir, args):
    """è‹¥ç”¨æˆ·æŒ‡å®š --split, è°ƒç”¨ coco_dataset_split.py è¿›è¡Œå†åˆ’åˆ†ã€‚"""
    ratios = [args.train_ratio, args.val_ratio, args.test_ratio]
    if abs(sum(ratios) - 1.0) > 1e-6:
        print('âš ï¸ åˆ’åˆ†æ¯”ä¾‹ä¹‹å’Œéœ€ä¸º1.0, å·²å¿½ç•¥ split æ“ä½œ')
        return
    script = Path(__file__).parent / 'coco_dataset_split.py'
    if not script.exists():
        print('âš ï¸ æœªæ‰¾åˆ° coco_dataset_split.py, è·³è¿‡åˆ’åˆ†ã€‚')
        return
    cmd = [
        'python', str(script),
        '-i', str(temp_dir),
        '-o', str(output_dir),
        '--train_ratio', str(args.train_ratio),
        '--val_ratio', str(args.val_ratio),
        '--test_ratio', str(args.test_ratio),
        '--seed', str(args.seed)
    ]
    print('â–¶ è°ƒç”¨å¤–éƒ¨åˆ’åˆ†è„šæœ¬: ' + ' '.join(cmd))
    subprocess.run(cmd, check=False)


def parse_args():
    parser = argparse.ArgumentParser(
        description='YOLO è½¬ COCO å·¥å…· (å¤šç»“æ„æ”¯æŒ)',
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument('-d', '--dataset_dir', required=True, help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('-o', '--output_dir', required=False, help='è¾“å‡ºè·¯å¾„(å¯é€‰):\n'
                                                           '  A) å½“è¾“å…¥ä¸ºæ ¼å¼ä¸€/æ ¼å¼äºŒä¸”æœªæä¾› -o æ—¶: é»˜è®¤å†™å…¥ <dataset_dir>/annotations/*.json\n'
                                                           '  B) å½“è¾“å…¥ä¸º standard/mixed ä¸”æœªæä¾› -o ä¸”æœªä½¿ç”¨ --split: é»˜è®¤å†™å…¥ <dataset_dir>/annotations.json\n'
                                                           '  C) å½“è¾“å…¥ä¸º standard/mixed ä¸”ä½¿ç”¨ --split: å¿…é¡»æä¾› -o ä½œä¸ºåˆ’åˆ†è¾“å‡ºç›®å½•\n'
                                                           '  æŒ‡å®šåè¡Œä¸ºä¸æ­¤å‰è¯´æ˜ä¸€è‡´ã€‚')
    parser.add_argument('--split', action='store_true', help='å½“è¾“å…¥ä¸ºæ ‡å‡†æˆ–æ··åˆç»“æ„æ—¶, å…ˆè½¬æ¢å†æŒ‰æ¯”ä¾‹è°ƒç”¨ coco_dataset_split åˆ’åˆ†')
    parser.add_argument('--train_ratio', type=float, default=0.8, help='(å¯é€‰) åˆ’åˆ†è®­ç»ƒé›†æ¯”ä¾‹')
    parser.add_argument('--val_ratio', type=float, default=0.1, help='(å¯é€‰) åˆ’åˆ†éªŒè¯é›†æ¯”ä¾‹')
    parser.add_argument('--test_ratio', type=float, default=0.1, help='(å¯é€‰) åˆ’åˆ†æµ‹è¯•é›†æ¯”ä¾‹')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­(ä¼ é€’ç»™åˆ’åˆ†è„šæœ¬)')
    return parser.parse_args()


def main():
    args = parse_args()
    dataset_dir = args.dataset_dir
    if not os.path.exists(dataset_dir):
        print(f'âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}')
        return

    structure, paths = detect_structure(dataset_dir)
    if structure == 'unknown':
        print('âŒ æ— æ³•è¯†åˆ«çš„æ•°æ®é›†ç»“æ„, è¯·ç¡®è®¤ç›®å½•ç»„ç»‡ã€‚')
        return
    print(f'ğŸ“ æ£€æµ‹åˆ°ç»“æ„: {structure}')

    classes = load_classes(dataset_dir)
    if classes:
        print(f'ğŸ“‹ åŠ è½½ç±»åˆ«æ•°: {len(classes)}')
    else:
        print('âš ï¸ æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶, å°†æŒ‰æ ‡ç­¾æ–‡ä»¶åŠ¨æ€æ‰©å±•ç±»åˆ«ã€‚')

    output = args.output_dir  # å¯èƒ½ä¸º None
    # å…ˆæ£€æµ‹ç»“æ„å†å†³å®šé»˜è®¤è¾“å‡º

    # ç»“æ„å·²å¸¦åˆ†å‰²(format1/format2) -> ä¸ºæ¯ä¸ª split å•ç‹¬ç”Ÿæˆ JSON
    if structure in ['format1', 'format2']:
        if output is None:
            if structure == 'format1':
                print('â„¹ï¸ æ ¼å¼ä¸€æœªæä¾› -oï¼Œé»˜è®¤å†™å…¥ <dataset_dir>/<split>/annotations/<split>.json')
                for split_name, img_dir, lbl_dir in paths:
                    coco_dict = convert_split(split_name, img_dir, lbl_dir, classes)
                    split_ann_dir = Path(dataset_dir) / split_name / 'annotations'
                    split_ann_dir.mkdir(parents=True, exist_ok=True)
                    save_coco(coco_dict, str(split_ann_dir / f'{split_name}.json'))
                print('ğŸ‰ è½¬æ¢å®Œæˆ (æ ¼å¼ä¸€å¤šåˆ†å‰²é»˜è®¤è·¯å¾„æ›´æ–°ä¸º <split>.json).')
                return
            else:  # format2
                out_dir = Path(dataset_dir) / 'annotations'
                print(f'â„¹ï¸ æ ¼å¼äºŒæœªæä¾› -oï¼Œé»˜è®¤å†™å…¥ {out_dir} ä¸‹ train/val/test.json')
                out_dir.mkdir(parents=True, exist_ok=True)
                for split_name, img_dir, lbl_dir in paths:
                    coco_dict = convert_split(split_name, img_dir, lbl_dir, classes)
                    save_coco(coco_dict, str(out_dir / f'{split_name}.json'))
                print('ğŸ‰ è½¬æ¢å®Œæˆ (æ ¼å¼äºŒå¤šåˆ†å‰²é»˜è®¤è·¯å¾„).')
                return
        else:
            # ç”¨æˆ·æ˜¾å¼æä¾›è¾“å‡ºç›®å½•ï¼Œæ²¿ç”¨åŸå…ˆè¡Œä¸ºï¼šç›®å½•ä¸‹ train.json/val.json/test.json
            out_dir = Path(output)
            out_dir.mkdir(parents=True, exist_ok=True)
            for split_name, img_dir, lbl_dir in paths:
                coco_dict = convert_split(split_name, img_dir, lbl_dir, classes)
                save_coco(coco_dict, str(out_dir / f'{split_name}.json'))
            print('ğŸ‰ è½¬æ¢å®Œæˆ (å¤šåˆ†å‰²è‡ªå®šä¹‰è¾“å‡º).')
            return

    # æ ‡å‡† / æ··åˆ ç»“æ„
    split_name, img_dir, lbl_dir = paths[0]
    coco_dict = convert_split(split_name, img_dir, lbl_dir, classes)

    if args.split and structure in ['standard', 'mixed']:
        if output is None:
            print('âŒ standard/mixed ä¸”ä½¿ç”¨ --split æ—¶å¿…é¡»æŒ‡å®š -o è¾“å‡ºç›®å½•')
            return
        output_path = Path(output)
        # å…ˆè¾“å‡ºåˆ°ä¸´æ—¶ç›®å½• temp/images + annotations.json, å†è°ƒç”¨å¤–éƒ¨åˆ’åˆ†
        with tempfile.TemporaryDirectory() as tmp:
            tmp_path = Path(tmp)
            # ä¿å­˜ annotations.json
            save_coco(coco_dict, str(tmp_path / 'annotations.json'))
            # æ‹·è´å›¾ç‰‡ (COCO åˆ’åˆ†è„šæœ¬éœ€è¦ images/ ç›®å½•)
            images_out = tmp_path / 'images'
            images_out.mkdir(exist_ok=True)
            for f in iter_images(img_dir):
                src = Path(img_dir) / f
                dst = images_out / f
                try:
                    if src != dst:
                        # å¤åˆ¶å›¾ç‰‡
                        with open(src, 'rb') as fr, open(dst, 'wb') as fw:
                            fw.write(fr.read())
                except Exception as e:
                    print(f'å¤åˆ¶å›¾ç‰‡å¤±è´¥: {src} -> {dst}: {e}')
            # åŒæ—¶ä¿å­˜ classes.txt (è‹¥å­˜åœ¨)
            if classes:
                with open(tmp_path / 'classes.txt', 'w', encoding='utf-8') as f:
                    f.write('\n'.join(classes))
            # è°ƒç”¨åˆ’åˆ†è„šæœ¬
            maybe_split(tmp_path, output_path, args)
        print('ğŸ‰ è½¬æ¢å¹¶åˆ’åˆ†å®Œæˆ.')
        return

    # ä¸åˆ’åˆ†: è¾“å‡ºå•ä¸€ JSON
    if output is None:
        # é»˜è®¤è¾“å‡ºåˆ°æ•°æ®é›†æ ¹ç›®å½• annotations.json
        default_file = Path(dataset_dir) / 'annotations.json'
        print(f'â„¹ï¸ æœªæä¾› -oï¼Œå†™å…¥é»˜è®¤æ–‡ä»¶: {default_file}')
        save_coco(coco_dict, str(default_file))
    else:
        output_path = Path(output)
        if output_path.suffix.lower() == '.json':
            save_coco(coco_dict, str(output_path))
        else:
            output_path.mkdir(parents=True, exist_ok=True)
            save_coco(coco_dict, str(output_path / 'annotations.json'))
    print('ğŸ‰ è½¬æ¢å®Œæˆ (å•æ–‡ä»¶).')


if __name__ == '__main__':
    main()